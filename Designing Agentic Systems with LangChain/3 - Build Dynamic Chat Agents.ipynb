{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Defining multiple tools**\n",
    "\n",
    "Now that we know how to integrate external tools with chatbots, let's learn how to build a multiple-tool chatbot that can automate selecting a tool per query.\n",
    "\n",
    "### **Enhancing an education chatbot**\n",
    "\n",
    "Let's imagine our school wants to enhance their chatbot further.:\n",
    "- For _history_ lessons, they'd like to incorporate a tool that looks up _historical events_. \n",
    "- or _English_ lessons, they'd like to feature a _palindrome_ tool that checks whether a specific string is the same when reversed, for example the word \"level\", or the phrase \"top spot\".\n",
    "\n",
    "We can use a different approach for each tool:\n",
    "- For historical events, we'll create a tool that directly _invokes the LLM_ to look up natural language dates, such as \"5th of November\".\n",
    "- To build a palindrome checker, we'll use standard Python to compare a reversed string to its original <br>\n",
    "  eg. `string == string[::-1]`\n",
    "\n",
    "Let's code the historical events tool first.\n",
    "\n",
    "### **Historical events tool**\n",
    "\n",
    "We'll label our tool with the LangChain $\\textcolor{green}{\\text{@tool}}$ decorator, helping the LLM to identify custom tools.\n",
    "\n",
    "Next, we'll call this tool `“date_checker”`, setting it to expect dates as _strings_. <br>\n",
    "We'll then write a docstring that provides the LLM with a general instruction to return important historical events by date. \n",
    "\n",
    "Next, we'll set up a _try-except_ block for different outputs. Within the try-except block, we'll use the `.invoke()` method to invoke the LLM with the given `date`, passing another instruction that events must relate to the provided date. After saving the response in a variable called `\"answer\"`, we'll return its content. \n",
    "\n",
    "If the LLM fails to respond, we'll define an `exception` that returns an error message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "from langchain_core.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "\n",
    "# Set up the API key\n",
    "api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "# Define the llm\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", api_key=api_key)\n",
    "\n",
    "######## ######## ########\n",
    "\n",
    "# Use a decaorator to label the tool and set the input format to string\n",
    "@tool\n",
    "def date_checker(date:str) -> str:\n",
    "    \"\"\"Provide a list of important historical events for a given date in any format.\"\"\"\n",
    "    try:\n",
    "        # Invoke the LLM to interpret the date and generate historical events\n",
    "        answer = llm.invoke(f\"List important historical events that occured on {date}\")\n",
    "\n",
    "        # Return the response\n",
    "        return answer.content\n",
    "\n",
    "    # Set an exception block for errors in retrieval\n",
    "    except Exception as e:\n",
    "        return f\"Error retrieving events: {str(e)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Palindrome tool**\n",
    "\n",
    "Next, we'll create our palindrome tool. Starting with a $\\textcolor{green}{\\text{@tool}}$ decorator, we'll name the tool \"`check_palindrome`\", then set the expected input to _string_. <br>\n",
    "Then we'll create a docstring with an instruction to check for a palindrome. \n",
    "\n",
    "We'll clean our text using `.isalnum()` to remove any _non-alphanumeric_ characters and use `.lower()` to turn the remaining characters into _lowercase_, saving the result as a variable called \"`cleaned`\". \n",
    "\n",
    "Next, we set up an _if-else_ statement that checks if the reversed version of \"`cleaned`\" is identical to the original, returning the appropriate response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "# Set input format to string\n",
    "def check_palindrome(text: str):\n",
    "    \"\"\"Check if a word or phrase is palindrome.\"\"\"\n",
    "\n",
    "    # Remove non-alphanumeric characters and convert to lowercase\n",
    "    cleaned = ''.join(char.lower() for char in text if char.isalnum())\n",
    "\n",
    "    # Check if the reversed text is the same as original text\n",
    "    if cleaned==cleaned[::-1]:\n",
    "        return f\"The phrase or word '{text}' is a palindrome.\"\n",
    "    else:\n",
    "        return f\"The phrase or word '{text}' is not a palindrome.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Binding multiple tools**\n",
    "\n",
    "Now we'll add these tools to a new chatbot. \n",
    "\n",
    "We'll import the `ToolNode` sub-module from `langgraph.prebuilt`, defining our tools list with the original `wikipedia_tool`, `date_checker`, and `check_palindrome` tools. This list could feature any tools you'd like your chatbot to have. \n",
    "\n",
    "We'll then create a `tool_node`, passing `\"tools\"` to the `ToolNode()` class. \n",
    "\n",
    "Finally, we'll bind the tools to our `llm`, creating `\"model_with_tools\"` using the `.bind_tools()` method.\n",
    "\n",
    "Note: Since `wikipedia_tool` is defined in the previous chapter, we'll define it again here first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules required for defining tool nodes\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "# Import Wikipedia tool\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "from langchain_community.tools import WikipediaQueryRun\n",
    "\n",
    "# initialize Wikipedia API wrapper to fetch top 1 result\n",
    "api_wrapper = WikipediaAPIWrapper(top_k_results=1)\n",
    "\n",
    "# Create a Wikipedia query tool using the API wrapper\n",
    "wikipedia_tool = WikipediaQueryRun(api_wrapper=api_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of tools\n",
    "tools = [wikipedia_tool, date_checker, check_palindrome]\n",
    "\n",
    "# Pass the tools to the ToolNode()\n",
    "tool_node = ToolNode(tools)\n",
    "\n",
    "# Bind tools to the LLM\n",
    "model_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Defining nodes and edges for flexible function calling**\n",
    "\n",
    "Now that our palindrome, historical events, and Wikipedia tools are ready to go, let's incorporate them into a new chatbot workflow.\n",
    "\n",
    "### **Define workflow functions**\n",
    "\n",
    "Let's start building the first of two workflow functions, which is a __stopping function__ that \n",
    "- check for tools calls, or\n",
    "- end the conversation if there is no tool call in the last message.\n",
    "\n",
    "The next function is a __dynamic tool caller__ that\n",
    "- returns a tool response if tool call present, or\n",
    "- invokes the LLm with chatbot node if there are no tool calls.\n",
    "\n",
    "Once these functions are set u, we'll define the full graph.\n",
    "\n",
    "### **Create a stop condition function**\n",
    "\n",
    "To build the workflow, we'll import the `MessagesState`, `START`, and `END` modules from `langgraph.graph`. \n",
    "\n",
    "Then, we'll define the stop condition function called \"`should_continue`\" that accepts `MessagesState` to define the graph state. We'll then extract the last message from \"`messages`\" in \"`state`\" and save it as `last_message`. \n",
    "\n",
    "Then we'll check if this message has tool calls, such as \"`wikipedia`\", returning \"`tools`\" if the condition is true. If not, the conversation is ended using \"`END`\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState, START, END\n",
    "\n",
    "# Use MessagesState to define the state of the stopping function\n",
    "def should_continue(state: MessagesState):\n",
    "\n",
    "    # Get the last message from the state\n",
    "    last_message = state[\"messages\"][-1]\n",
    "\n",
    "    # Check if the last message includes tool callls\n",
    "    if last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    \n",
    "    # End the conversation if no tool calls are present\n",
    "    return END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Create a dynamic tool caller**\n",
    "\n",
    "Next, we'll create our dynamic tool caller named \"`call_model`\", which also accepts `MessagesState` as the graph state, saving the last message as a variable called `last_message`. \n",
    "\n",
    "Then we'll use `isinstance()` to check if this message is an `AIMessage` from the chatbot and whether it features `tool_calls`. <br>\n",
    "If so, we'll return the \"`response`\" from \"`tool_calls`\", passed to the content field of the `AIMessage`. <br>\n",
    "If there are no `tool_calls`, we'll invoke the model using all of the \"`messages`\" in the state, passed as an argument to the `.invoke()` method before it's applied to `model_with_tools`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to import the AIMessage class\n",
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "# Extract the last message from the history\n",
    "def call_model(state: MessagesState):\n",
    "    last_message = state[\"messages\"][-1]\n",
    "\n",
    "    # If the last message has tool calls, return the tool's response\n",
    "    if isinstance(last_message, AIMessage) and last_message.tool_calls:\n",
    "\n",
    "        # Return the messages from the tool call\n",
    "        return {\"messages\": [AIMessage(content=last_message.tool_calls[0][\"response\"])]}\n",
    "    \n",
    "    # Otherwise, proceed with a regular LLM response\n",
    "    return {\"messages\": [model_with_tools.invoke(state[\"messages\"])]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Create the graph**\n",
    "\n",
    "Sinve we've now got our functions, let's create the full graph!\n",
    "\n",
    "Our graph state called \"`workflow`\" will be created for us using the `MessagesState` passed to `StateGraph()`.\n",
    "\n",
    "Then we'll add our nodes to the workflow, mapping the \"`chatbot`\" to the \"`call_model`\" function, and \"`tools`\" to our `tool_node`.\n",
    "\n",
    "We'll then add a `START` node that initializes the \"`chatbot`\" node, before adding conditional edges from the \"`chatbot`\" to the `END` or \"`tools`\" nodes using our \"`should_continue`\" function.\n",
    "\n",
    "Next, we'll add another edge from the \"`tool`\" node back to the \"`chatbot`\", completing the conversation loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x314ac7320>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import required classes\n",
    "from langgraph.graph import StateGraph\n",
    "\n",
    "workflow = StateGraph(MessagesState)\n",
    "\n",
    "# Add nodes for chatbot and tools\n",
    "workflow.add_node(\"chatbot\", call_model)\n",
    "workflow.add_node(\"tools\", tool_node)\n",
    "\n",
    "# Connect the START node to the chatbot\n",
    "workflow.add_edge(START, \"chatbot\")\n",
    "\n",
    "# Define conditions, then loop back to chatbot\n",
    "workflow.add_conditional_edges(\"chatbot\", should_continue, [\"tools\", END])\n",
    "workflow.add_edge(\"tools\", \"chatbot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Adding memory**\n",
    "\n",
    "We'll then create a `MemorySaver()` object called `\"memory\"`, which we'll use to enhance our chatbot with memory. \n",
    "\n",
    "Next, we'll apply the `.compile()` method to our workflow, passing in the memory to the \"`checkpointer`\" to create the chatbot application, before displaying the LangGraph diagram. Later on, we'll test this workflow with different queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANYAAAD5CAIAAADUe1yaAAAAAXNSR0IArs4c6QAAIABJREFUeJzt3XlYE9feB/AzScieAAk7kV0EBFdcQXEtda3Y1laxLq193G2va721ajdfa6v1tr3WtnrdsO4bWBVU1LrhjgooKgIKGAiEJCRkz7x/hIdSDJvNzJmQ83n6R80y54d+OTNz5swZDMdxgCDw0GAXgDg7FEEEMhRBBDIUQQQyFEEEMhRBBDIG7AJehUpuVFUZa1VmTY3JZHCMYSWGC0ZnYFwBnStkiH2ZbC4ddkVUgTnGPyAAAABZqa7grqYwV8MTMswmnCuk8wQMJocGHOEnYLAwdbWptsZcqzJplGaeKz04mtexG5/v7gK7NMgcI4LKKuOV1Eq6C+buxQzuzPPwZ8Gu6J8qLdAW5mjkUr2bJ7P/GDHDxXmPiBwggtdOVuXfrOk/1iOsKx92LfZ390/FlbSqAUke0f1dYdcCB9UjePA/JdFxwohYIexCiHU9XV4jNw6d6A27EAioG0Ecx39d/nTsTD/fYA7sWsiQd01VlKsZ+b4v7ELIRt0I/rz0yZQVQTyhQ56zv5qHN1Q5V1RvfSSBXQipKBrBgxtL4saJfYOcov9r6P5lZVWZftDbXrALIQ8VT8SyTlTFDBA6Yf4AADFxrlwB/cF1FexCyEO5CFZXGJ5kqzv1bOfnH83oMdT9/AEZ7CrIQ7kIXkmr6j9GDLsKmBgutJ7D3K+drIJdCEmoFUFpkY7FoYXEtMPxvzbpnSiSFumMBgvsQshArQgW3FOLfJikNZeTk6PX62F9vXlsHr0wR0PQximFWhEszNUEd+aR01ZaWtq0adO0Wi2Ur7coOJqHIki26gqDUMRw9yapF3zlDsw6jEVc/2cVEsNTVhkJbYIiKBRBZaURwzAitlxcXDxr1qz4+PiRI0euWbPGYrGkpaWtXbsWADBs2LDY2Ni0tDQAQHZ29rx58+Lj4+Pj42fOnPngwQPr1xUKRWxs7K5du1asWBEfH//hhx/a/Lp9MVxoaoVJozTZfctUQ6FrD7UqM1dIyCy6L7/8sqioaNGiRRqN5ubNmzQaLS4ubvLkySkpKRs3buTz+QEBAQCAsrIyvV4/Y8YMGo124MCBBQsWpKWlsdls60a2bt369ttvb968mU6ne3t7v/x1u+MJGRqViedKoX8jIlDox9OoTARdjisrK4uIiEhKSgIATJ48GQAgEokkEgkAIDo62s3NzfqxESNGjBw50vr/UVFRs2bNys7O7tu3r/WVmJiYuXPn1m/z5a/bHc+VrlGaQQeCNk8VFIogADiDRciOeOTIkdu3b1+3bt2MGTNEIlFTH8Mw7Ny5cykpKYWFhVwuFwBQVfXX4Fzv3r2JqK0ZLDYdt1Dx8ql9UehYkMNj1MgJOfSZO3fuwoULMzIyxo4du3///qY+tmXLliVLlkRFRW3YsOHjjz8GAFgsf43McThkXzBUVBq4TjBLg0IR5ArptSozEVvGMGzSpEnHjh1LSEhYt25ddnZ2/Vv1szT0ev22bdvGjRu3aNGibt26xcTEtGbLhE7yIO7gmFIoFEGByMWFmB2xdQCFx+PNmjULAPDw4cP6Xk0mq7saq9Vq9Xp9ZGSk9Y8KhaJRL9hIo68TQSBiCNzafy9IoZ/Q059V+kSrVpj49v57X7ZsGZ/P79u376VLlwAA1px17dqVTqd/9913Y8eO1ev1b775ZlhY2N69e8VisVqt/vXXX2k02pMnT5ra5stft2/NRXkaFyYNoxHyO0kp9NWrV8Ou4S8KmdGos3gFsO272ZKSkkuXLp06dUqr1c6fP3/QoEEAAKFQ6O3tffr06YsXL6pUqtGjR/fo0ePy5cv79+8vLi6eP39+YGDgoUOHkpOTjUbjzp074+Pjo6Ki6rf58tftW/Odcwr/MI5XBzv/VVAQtaasPnuoeZqjGfSWE03YbErar2WDJ3jy3dr/LZ4U2hEDAAIieNdOyqXFOp9A27/9CoVi3LhxNt+SSCQlJSUvv56QkPD555/bu9LGZsyYYXOvHRkZWX+VpaGePXuuX7++qa3lXFHy3RjOkD/K9YIAgNIn2munqsbPs33/hNlsLi8vt/kWhtn+WTgcjru7u73LbEwmkxmNNi7pNlUVi8USi5ucFvnr8qdTVwayOO3/dJiKEQQAnNtf0bE7X9KRC7sQOO5fVhp0lp5DCf+1oQgKDcrUGzzB69QOqVZNyBghxT3Lr316T+08+aNoBAEAE5cG/P7NM9hVkK2m2ng6pfyN2f6wCyEVFXfEVnqteffaZ8mfBDjJIVF5sS4jpTx5eQDNCcYCG6JuBK29wp51z8fO9PVp7zd05t9S3f1TOeFf7X1WjC2UjqDV2T3lWo05bowHaROqyVTyuPZyWpUkjBM31gN2LXA4QAQBAIU5mstplSExPO8AdnA0rx3sqnQac2Gu5kWhTllpjBsjtvsFIQfiGBG0enyn5vEddWGOJrKPkMHEeEIGz5XOYtMd4geg0zGNylSrMqmVJpXcVF6sC+7MC+8pCOjkpGNP9RwpgvWKHmiUFUaNyqRRmk0mi8WuozdGozEvL69r16723CgAHD4dt+BcIYPvyhD7Mv1C2/nRbes5ZAQJVVVVNXHixIyMDNiFOAuKjgsizgNFEIEMRbAxDMPCw8NhV+FEUAQbw3H80aNHsKtwIiiCjWEY5urqpIvfQ4Ei2BiO40qlEnYVTgRF0AYfHx/YJTgRFEEbpFIp7BKcCIpgYxiGNbxTDiEaimBjOI7n5eXBrsKJoAgikKEINoZhWDOrbyF2hyLYGI7jcrkcdhVOBEXQBg8PJ53ADAWKoA2VlZWwS3AiKIIIZCiCjWEYFhoaCrsKJ4Ii2BiO4wUFBbCrcCIogghkKII21C/3i5AARdAGmysCIgRBEUQgQxFsDM2UIRmKYGNopgzJUAQRyFAEG0M3cZIMRbAxdBMnyVAEEchQBBtD9xGTDEWwMXQfMclQBBtDM2VIhiLYGJopQzIUQQQyFEEbvL29YZfgRFAEbWjqSYsIEVAEbUDzBcmEImgDmi9IJhTBxtBkLZKhCDaGJmuRDEXQBonE9jPhESKgR9/U+eCDD6RSKZ1Ot1gs1dXVIpEIwzCTyXTixAnYpbVzqBesM2HChJqamrKyMqlUqtfrX7x4UVZWhmEO/7xF6kMRrJOYmBgSEtLwFRzHe/bsCa8iZ4Ei+JeJEydyuX89F9PHx2fSpElQK3IKKIJ/SUxMDAwMtP6/tQuMiIiAXVT7hyL4N1OmTOHxeNYucOLEibDLcQoogn8zfPjwwMBAHMe7d++OLtORgwG7gBboNObKMoNBbyGtxXGvzQS1R18fOPVpjoa0Rrk8usjPhcmik9YidVB3XNBswjNSpCWPtJJwnpHECEJh1Fvk5bqwboLBb3vBroVsFI2gXms+9ENpz0QPv2BuKz7eTjy4rigv0o750Bd2IaSiaAR3rSke/I6vqwcTdiFke5KtkhbWjpjmRA/Bo+LpSG6WMiiK74T5AwCEdRPiFlD2VAu7EPJQMYIVz/QcAdXPk4jjwqJVvTDAroI8VIygQWcRilxgVwGNmw9LozTBroI8VIygrtZiNsMuAh6zATcZqXiAThAqRhBxKiiCCGQogghkKIIIZCiCCGQogghkKIIIZCiCCGQogghkKIIIZCiCCGTtOYKPn+QPHhp79erFNn3LbDbfv5/d8JUVKxfNnDW5ra2/vB3EpvYcwVfz7fovN2xcQ53ttHsogo0Z9HpKbafdayczQ3U63a6ULefOZcgqK7y9fV8bPip50nTrW4VFBXv378zPz5NIAj6avywmphsAoKKifOu2TdeuXdZo1B06BE6aOH3Y0NcBAGvXrT53/jQAYPDQWADA77tTfX38AACaWs2q1Utv37nOZLKGDnn9g/fnsFgsAIDJZNq2fXN6xnGlUhEYGDxt6sz4uEEvb+fg/lNisQfsvySKag8RNJvN//704/s52eOT3g0LDS8qfvq8pJhOr7shMmX31glvvzfi9bG/79n+6WcLf09J5fP5JrPp4cPcN8a+5Sp0+/NS5tdrVvj7d4iM6Dx50vuyivIXL0qXf/IFAEAsqstNefmLfn0HzJ2z6MaNqwcO7i4te/71lxsAAN+t/+rM2ZOTk98PCgo9c/bkZysX/+f737p06d5oO66ublD/hiitPUTwwp9n72TfXLL4s5Ej3nj53Y/mL0tMHA0ACAwInjNv2q3b1xIGDvXz9d/+vwPWhbNGjHgj6c1hly+fj4zoLJEEuLq6yaurrJ1lvZDgsLlzFgIAXk8c4+Hhtf9Ayt27t93dRekZx6e8N2Pa1JkAgISBQydPSdq+45cN6zc3tR3kZe0hgtdvXGGxWImvjbb5rlBY90C5oKBQAIBMVrea/pOCR9t3/JKfn2ftR+XyqlY2lzTunf0HUu5k37TuW+PjB1tfxzCsV2zf02fQeoRt0x5OR6rlVR5iz/o9b1NoNJo1bQCA23duzJk71WgwLF2y6vNV64RCVwve2rvlPTw8AQAajVqjUQMA3N1E9W8Jha61tbUaDXnLMLQD7aEX5PMF8urW9mFWu3Zt8fOTrPl6I4PBAABw2JyG7zZ/b7VCUQ0AcHcXeXh4AQBUKqU1lAAAubyKwWCw2ezWbAexag+9YPfuvbRa7dnM9PpXTKYW7kBTqhRhoeHW/BkMhlptrcVS1wuy2Ry5vKr+jy+7cOEMAKBHj96RkdEYhmVdu2R93WAwZF271LlzF2t/3OJ2EKv20AsOHzby6LH9a79Z9fBhblho+NPCJ7duX/t18+5mvtKtW2x6etqJk8eEAtcDh3bX1KiKCgtwHMcwrGuXHidPpW74fk1MdDeBQNi//0AAQMHTx//dtCE0tGN+fl7a8cMJA4dGdIoCACS+Nnr7jl/MZrOfn+SPP47I5VX/Xv6ltYmG2/Hzk6Dzkqa0hwiyWKz1323+7bcfT585cfyPwz4+foMHvdZ8R/j+tNnyqsoff/pWIBCOHjV+wluTN2xccyf7Zo/uvYYPH5n/KC/j9B9Xsy6+njjGGsGJ707Nybl7/I/DPB7/7beSp0+bZd3Oxx99wuPxjxzdV1OjCg4KXfPV9z2697K+1XA7U977EEWwKVRcU+bY5rLwWDdJRyda0Kih3CsKk8EU/4azDGW3h2NBxKGhCCKQoQgikKEIIpChCCKQoQgikKEIIpChCCKQoQgikKEIIpChCCKQoQgikKEIIpBRcbKWUOxCo1Fu/g5p6AzMqZ6HSMVekMOjyUqc9z5waVGtUOxEj12hYgQDI7mqSid6/FAjWrU5IJzTig+2E1SMoG8wR+zHvJJaAbsQCE6nlPYc6sbkONGOmIqzpq1uZ1aXPdX5d+R5+rMZTCr+qtiRTm2qkurvX6oe8o5XQCfnmi5O3QgCAJ7la/JvqmtrzNXlf9svm81mo9FYf6+kfeE4rtPpOBySdoVarZbFYglFLE8Js/sgN6c6CqyDO6D58+cTt/GNGzfGx8enpqYS10RDFRUVK1euJKctaqJ0L/iyzMzMIUOGELf9Fy9ezJ8/v6ioKDIycteuXcQ19LKdO3cOHTrU39+fzEapwJGOsd555x2i/4UOHDhQVFQEAHj27Nnx48cJbauRkSNHzp49W+98qxI6Ri8olUpdXV1LS0vDwsKIa6W0tHTBggXFxcXWP5LfEVoPDe/duxcVFSUQCEhuGhYH6AUPHDiQlZXF4XAIzR8A4MiRI/X5AwAUFxcfO3aM0BZfxuFwOnbsOGbMGLVaTXLTsDhABIuLi8eNG0d0K2VlZefOnWv4ikaj2b27uVVBCCISic6fP6/T6aRSKfmtk4/SEbxy5QoAYPHixSS0tXfvXmsXWL8QEYZhz58/J6Fpmzw8PPh8flxcXMOOuX2CfUpum8Fg6N+/f3V1NflNy2Sy1157jfx2bdJqtdu2bYNdBbGo2AsqFIri4uKzZ8+6uUFYotlsNkdERJDfrk1sNnvatGkAgE8//dS6OGf7Q7kIpqamFhUVhYWFEXTxo0VGo9E6LkMp06dP//jjj2FXQQhqRVAmk925c6dbN5jroGm1Wm9vb4gF2BQWFvbjjz8CAM6fPw+7FjujUASLioowDFu1ahXcMqqqqlxcqHuh1mg0Ll26FHYV9kSVCK5cuZLD4Xh4wF9Ur7q6OiAgAHYVTRo+fPioUaNas5ixo6BEBEtKSvr06UOR3V9hYSEVfhOakZCQAADYt2/fo0ePYNdiB/AjqNVq+Xy+9TebCvR6fWhoKOwqWpacnLxq1ap2cJoMOYJLliy5evUqlMGXpmRmZoaHh8OuolX27NljMpny8/NhF/KPwIzgrVu3FixYQOjkq7ZSKBRCodDPzw92Ia3FYrHkcvnOnTthF/LqoEVQLpd37NixQ4cOsAqwKSsrKygoCHYVbdOvX7/q6mrYVbw6OBE8ePDgL7/8IhQKobTejD///HPgwIGwq2izjz76yGAwOOhcQwgRlEqlbm5uy5cvJ7/pFimVSkeMIACAyWRu2rQpJSUFdiFt5hhTVsmRnp5+4cKFNWvWwC7k1V27ds3Dw8Mhzujrkd0Lzps3Lycnh+RGW+nIkSNJSUmwq/hH+vTpExgY6FgPviM1ghcuXBgzZkx0dDSZjbZSYWEhg8Ho1asX7EL+KQaDMXz4cIVCAbuQ1kI74jqLFy8eNWrU4MGDYRdiB0ql8vjx48nJybALaRXyesF9+/ZRdhf88OHDFy9etI/8AQBcXV0dJX/kRbCoqGj//v3U3AUDAL7//ntybg8g05IlS+7evQu7ipaRFEEMw7Zs2UJOW2119OhRiUTSvXt32IXY2ZIlS3744QfYVbTM2Y8FTSZTYmLi2bNnYRfivMjoBTMzM7/44gsSGnoFCxcupGxtdpGRkQG7hBaQEcGsrKx+/fqR0FBb7dq1KyQkJC4uDnYhBHr06NG2bdtgV9Ec590RP378+Mcff3SIo6V/wmQypaWlUXnInYwIGgwGJpNJdCtt1bt376tXr9LpTrSeKTURviPOzc2dMWMG0a201eTJk3fs2OEk+cvJydm0aRPsKppEeATVajXRyxG11U8//ZScnBwZGQm7EJJER0fv3r1bp9PBLsQ2pzsW3LJli9FonD17NuxCSFVSUsLj8dzd3WEXYgPhvaDJZDIYqPIEh9TU1NLSUmfLHwBAIpFQM39kRDAzMxP63elWN27cyM3NpUgxJKuoqJgzZw7sKmwj/AFgYrGYCtPX7t27t2nTJoqPkBHHy8srPz9foVBQ6mZFK6c4FiwoKFi+fPn+/fthFwKTxWLBMAzDMNiFNNb+xwVLSkoWLFhw+PBhWAUgzSPjAl1SUhKsNWsfP348Z84clD/rqdjPP/8MuwobyHgY7KBBg6ZOnWo2m1UqlZeXF2kPU3j48OHevXtTU1PJaY7iBAJBQUEB7CpsIDCCAwcOrK2tta4lbD0EwXE8KiqKuBYbKigo+PTTTw8dOkROc9Q3YMCArl27wq7CBgJ3xEOGDKHRaNb5qtZXWCxWnz59iGuxXk5Ozm+//Yby1xCDwRCJRLCrsIHACK5evToqKqrh6Y6npycJv4jZ2dnffvvt2rVriW7IschkstGjR8OuwgZiT0e++eab+iVacBzncrlEXy++ePHi8ePHd+zYQWgrjojJZFqPi6iG2Ah6e3v/61//sq4YiWEY0V1genr6oUOHVqxYQWgrDkooFFLz9h3CB2Xi4+PHjx/P4/H4fD6hB4JHjx69cOHCxo0biWvCoWEYFhISArsKG1p1RmwyWrTqV7/INvHt94sLKgoKCkICOtdUE7JC8rlz53LvP3Xo5WCIZjQa33rrLfKfqteiFq6OPLiuundRKZcaOPx/NLuzflyGIAaDwcufX1ZQG9KF32u4u9iPRVxbjmXJkiVnz56tHxSzdoc4jt++fRt2aXWa6wWvZ8gry4wDxvsIRNR9CEJDFjOukBlObJcOm+TtGwTnyTlUM3v27Ly8vPLy8oajY5RaxrPJY8Frp+RKmWlAkrej5A8AQKNjIh/WuLmBZ/dUlD+j6CRhkoWEhPTs2bPhvg7DMEqtoWg7gtUVhspSfd/RXqTXYx9DJvrezHDgtW/ta8qUKQ0fqCGRSN59912oFf2N7QhWlupxnHKzelpP4O7y/HGtQQ9/niIVhIWF9e7d2/r/OI4PGDCAIo94sbIdQbXS7NnBsY+lAqN48hcOufYyEd577z0vLy8AgL+/P9UW3bIdQaPeYtQ5dheiqjIB4MAduX2Fhob26dMHx/GEhARKdYEkTdZC2spiwZ89rFVXmzQqk8mIazV2eMRSV7/Juu4dO4nizuwp/+dbY3PoTA6NK6QL3V0CIrj/ZFMogtTy4Loq/5a65HGtX7jQZMDpLnSaCwNg9hiUoLF79xtltACjPS4U16hxs9FkNhldXPSpv5QFRvHCu/M7xQpeYVMoglSRd0116VilZ4CAwRNED6fWvrJ57oGimora3Fu6y2lVA8aJO3ZvWxBRBOHTqs0ntpUbzbSQPhIG0/HWGMEwTOjNA4DH9xTezJQ/uKEe9YEPnd7aA3H4T+J0cs/yNTu/Lub7i3w6eTpi/hpichi+UV5Md7fNSwsqnrf20gCKIEzlz3UXDss7DQxkcRzmElSL2Hxm52HBJ7aVq6patYoGiiA0hbnqjBRZh24O89TPNgnqJTm8SSotbrkvRBGEQ60wnd3TbvNnFRTrf/jHUpOxhQFmFEE4Tu0sD+rtD7sKwoX29fvjfy0MQ6IIQnDzdLUZMBkujn3y0RosHlOjwXKvKpv5DIogBFknqrzCKLrUmt15hYgup8mb+YA9I5j3IOcfPpX5/IUzg4fGPntWZL+iKOfWGbl/lIiCywsBAL5YN/rgMTvf/Mpg0cUBgpwrTXaEdovgqfS0ufOm6XRae22wvXpwQ812dexZSG3F4rMf3lQ39a7dIuigT6UnmUpu1GksHIFz3drCF3Nkz3XGJqZv2ucC3an0tI3/WQsAGDd+GABg2dJVryeOAQBkZPyxe8+2srISsdhj1Mik5EnTrUt8mEymbds3p2ccVyoVgYHB06bOjI8b9PJms7Iu/brlx7KyEh8fv7Fj3hqf9I5dqoXoeX6tu4RP0MafPL114vSmMukjAV8UFhw7YvhsocADALDi66FvjlmW8+B8Xv5lDpvft1fSa4PrnoFgNpvPnN+adfOowaANDelpNBJ1t4NHkKD4QW1YNxs/u316wT694ya8PRkA8H9fb/xh45Y+veMAAOnpx//vm1UdO0Z8tmLNoITh/9v28+7f6xY5/W79V/v27xo9KunTf3/l4+P32crF9+7dabTN2tra1V8sY7owFy1c0b/fwKoqmV1KhavyhRHHCTkFfFxw47edC7y9gieM+3Rg/0lPi+5s3jbXYKiL1N7Dn/v5hM/5YHOPriMyMn/Ly79sff3I8W9Pn98aEd4/afRipgtbq6shojYAgNmMVctsXyyxTy/o7i7y85MAACIjo11d3awTxLf8778xMd1W/PsrAMDAAUNqalR79+14c/zEysqK9IzjU96bMW3qTABAwsChk6ckbd/xy4b1mxtus1oh1+v1AwYMGT5shF2KpAKN0sRgcYjY8tE/1veNTUoaXfdI2/CwPt/+8E7+k6yYqEEAgN49xg5NmAYA8PMJv37r2KMnWVGd4krKHmbdPDI0YfqIYbMAALHdRxUUEnVnpwuLoW7iFnKiZsqUlDyrrJS9M+G9+ld69ep34uSxktJn+fl5AID4+LrnT2MY1iu27+kzJxptwc/Xv3PnLim7t7LZnDGjx1Pw+U2vQKs2s9ztPxwor35RLiuslD/Punm04esKZd2wMJNZl3s6ne4q9FKqZACA+3nnAQAD+0+s/zyGETVIx2DRalXkRlCtUQMA3Nz+Wk1MIBACACplFRqNGgDg3uAtodC1trZWo9E03AKGYWvX/LBl60+bf9l44GDK8mVfdO3ag6BqSUPQqso16ioAwPDBM7pE/e3B8gKBx8sfptEYFosZAKBQSNlsPo/rSkhNjeCYpYmf3c6pr79f1cvTGwCgVCrq36qulluD6OHhBQBQqf4aKJLLqxgMBpvdeKiCz+d//NEnO7Yf4vH4Kz5bSM2FodqE50o36e0wC78RDlsAADAa9V6eQQ3/47CbO/Xh8dx1OrXRRMZTYUx6k8Dddn9ntwhy2BwAQGVl3UmDWOzh4+17/frl+g9cuHCGzWaHhXWKjIzGMCzr2iXr6waDIevapc6du9DpdKYLs2E6rQM9fr7+45PeVWvUUmmZvaqFReDKMBnsH0FPjwA3V58bt9P0hrpxWbPZZDIZm/+WxD8CAHDnXrrd63mZyWAWuNmOIH316tUvv1paoDWbgE9QGw6c2RzusdQDRcVPMYDlPbjfqVOUgC/cdyBFJis3Go2Hj+w9c/Zk8qT3e8X2FQqEUumLI0f3AYBVVsp+/vn7wqKCJYtX+vr6M1xcjhzd9zA/NyAgyEPsOWXa+MpKWVVV5ZGj+wx6/Qfvz2EwWnvk8PiOKiiSy2/ix4ZFrTRWSU0cNzufkWAY5u7me/1Wat7DizjAi5/fP3J8vdlsCOwQAwDIvLhT4hfRKaxuWbOsG0fZbF73Lq95eQTfyz17684JrU6t1lRfvXGkoPCmxC8yKiLevuUBAHRKTXAUW+Rt44DebhEUCoSent7nz5++evViTY0qMXF0WFi4u7so81zGyVOpimr5pEnTJye/b70w1Su2n0ajPnnqWGZmOo/LW7xoRa9e/QAAAr7A18fv9p0bNIwWGRVTUvLs0uVzFy9lisWenyxd7e8vaX091IwgV8i4/kelOND+h1/enkES/6inRdm3sk88K8n19Q3r2W2EdVywqQjSaLTI8HhZZfG93LNPi7J9vELk1WXensFERLDwVvmwZG8azcZlSdsra11Plxt0oOsgKi5N3EontpYkjPfwod7iRr+ve+4WIOa6OtEFkprKWpOqJmmu7cmR1OoknEFUX/6TXG0zEXz05PrOfctffp04rLhKAAACv0lEQVTDFjQ1dDw6cX7f2HH2qvBB/uXdB1e+/DqO4wDgNgduZk3/r8QvoqkN6tX6zr15Tb2LIki2bgPdrx4vcJcI6Qzb54JBAV0Wztn18us4DpqaXsPl2HPPHhrc02YBFosFx3GbzxEXCjyb2ppBa1RJ1ZG9mlxODkUQgrgx4rxbcp9ONgbtAABMJlvEhDmh374FVD6tHjBO3MwH0JRVCLoMcOOwzXptC4Mm7YCuRu8mxpq/uR1FEI4R032eZpXCroJYFgv+9HrZyOk+zX8MRRAOJos2brZf4fX2nMKnWSUTlwa0+DEUQWh8gznj5/kUXi+BXYj9mU2Wx5efTVomcfdqeXIJiiBMrmLmmBk+ORmFWlX7WRlbU617fOnZOwslXH6rTnZRBCHz8GfN3RBqUatKc8r1GjJmDBBHq9I/v/vCxaKe9U2osNWr5KNBGfgwDBv1gW9hjubPIxVcNzaDyxJ6cumOc5exSW9WyTRmvcGo0Q8a79EhvG0rXqIIUkVwNC84mldwX/34jubJZblIwjXqLXQmg8FiUHDFYhzHzXqT2WhyYdKqpdrgaF7HOH5Q1Kssi4giSC2hMfzQGD4A4EWhVqM0a5Qmg96is8dCv/bF4tLYXCZXyBW4070DWhh2aR6KIEX5BhNyiwkF2Y4gk41ZqNf5t4mrpwthN0Ig9mT7X0ng7iIrdux1EQrvqcW+7eGOp3bPdgS9OrAoueZJaylkhqDOXIYL6gYdQJO9oH8Y+89DUtLrsY+zu8v6jmxudgZCHc09jzj3qvJxtrprgtjdm9nU5DZK0apNykrjnwelb873d2vFpSGEClp4JHZhrib7gkJaqKMzqL5jFvmylDJDSDS39wgxT4jO9B1GCxGsp9dS/ZF0OA7YXAfoqpFGWhtBBCEI6jYQyFAEEchQBBHIUAQRyFAEEchQBBHI/h9Zsek9tetkAQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import the necessary classes\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# Set up memory and compile the workflow\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)\n",
    "\n",
    "display(Image(app.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Organize chatbot outputs with memory**\n",
    "\n",
    "### **Streaming multiple tool outputs**\n",
    "\n",
    "Now that our workflow is ready, we can test it! We'll first see whether the chatbot can answer a query by picking the correct tool. Then, we'll determine if the chatbot can interleave the user's queries with answers to follow-up questions.\n",
    "\n",
    "<div style=\"display: flex;\">\n",
    "    <!-- Left Column -->\n",
    "    <div style=\"width: 25%; padding: 10px;\">\n",
    "    Now that our workflow is ready, we can test it! We'll first see whether the chatbot can answer a query by picking the correct tool. Then, we'll determine if the chatbot can interleave the user's queries with answers to follow-up questions.\n",
    "    </div>\n",
    "    <!-- Right Column -->\n",
    "    <div style=\"width: 48%; padding: 10px;\">\n",
    "        <li><b>print outputs with multiple tools</b></li> <br>\n",
    "        <img src='./images/outputs.png' width=45%> <br><br>\n",
    "        <li><b>print outputs with multiple tools</b></li> <br>\n",
    "        <img src='./images/memory.png' width=45%>\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "\n",
    "To get started, we'll import the `AIMessage` and `HumanMessage` modules from the `langchain_core.messages` module, with a config variable set to one session. \n",
    "\n",
    "We'll create a function called `multi_tool_output` to handle queries for different tools. \n",
    "\n",
    "First, we'll define an \"`inputs`\" dictionary including the user's query as a `HumanMessage`, passed within the \"`content`\" field. \n",
    "\n",
    "Next, we'll stream messages and metadata using `app.stream()`, which accepts the \"`inputs`\" and \"`config`\", with \"`stream_mode`\" set to \"`messages`\" to enable real-time output. <br>\n",
    "For each message, if msg.`content` is not a `HumanMessage`, we'll print its contents to access just the chatbot responses. <br>\n",
    "We'll set the \"`end`\" parameter to an empty string to avoid excess line breaks, with \"`flush`\" set to \"`True`\" to ensure live outputs. <br>\n",
    "A line-space will separate the answers for different queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Create inout message with the user's query\n",
    "def multi_tool_output(query):\n",
    "    inputs = {\"messages\": [HumanMessage(content=query)]}\n",
    "\n",
    "    # Stream messages and metadata from the chatbot application\n",
    "    for msg, metadata in app.stream(inputs, config, stream_mode=\"messages\"):\n",
    "\n",
    "        # Check if the message has content and is not from a human\n",
    "        if msg.content and not isinstance(msg, HumanMessage):\n",
    "            print(msg.content, end=\"\", flush=True)\n",
    "    \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Test with multiple tools**\n",
    "\n",
    "Let's test this function with two queries using different tools. The first query should trigger the palindrome tool, since the question asks `\"Is 'Stella won no wallets' a palindrome?\"`. \n",
    "\n",
    "The second query should trigger the historical events tool, asking `\"What happened on April 12th, 1955?\"`.\n",
    "\n",
    "For each query, the chatbot will return a direct tool response before the LLM refines the output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The phrase or word 'Stella won no wallets' is a palindrome.Yes, the phrase \"Stella won no wallets\" is a palindrome.\n",
      "\n",
      "On April 12, 1955, one notable historical event occurred: **The first successful polio vaccine was announced by Dr. Jonas Salk**. On this day, Salk's vaccine was deemed effective in preventing poliomyelitis, a viral disease that had caused widespread fear and paralysis, particularly among children. This announcement marked a significant milestone in medical history and public health, leading to widespread vaccination campaigns and a dramatic decrease in polio cases in the following decades. \n",
      "\n",
      "If you're interested in other events or specific aspects of that day, feel free to ask!On April 12, 1955, one notable historical event occurred: **The first successful polio vaccine was announced by Dr. Jonas Salk**. On this day, Salk's vaccine was deemed effective in preventing poliomyelitis, a viral disease that had caused widespread fear and paralysis, particularly among children. This announcement marked a significant milestone in medical history and public health, leading to widespread vaccination campaigns and a dramatic decrease in polio cases in the following decades. \n",
      "\n",
      "If you're interested in other events or specific aspects of that day, feel free to ask!On April 12, 1955, a significant historical event took place: **The first successful polio vaccine was announced by Dr. Jonas Salk**. This announcement marked a milestone in medical history, as Salk's vaccine was deemed effective in preventing poliomyelitis, a viral disease that had caused widespread fear and paralysis, especially among children. The success of the vaccine led to extensive vaccination campaigns and a substantial decrease in polio cases in the following decades.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "multi_tool_output(\"Is `Stella won no wallets` a palindrome?\")\n",
    "multi_tool_output(\"What happened on April 12th, 1955?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the phrase in the first query is labeled a palindrome, with additional comments from the LLM. \n",
    "\n",
    "The next query referencing a date returns information about the polio vaccine breakthrough.\n",
    "\n",
    "Once again, the tool response is followed with an LLM refinement.\n",
    "\n",
    "### **Follow-up questions with multiple tools**\n",
    "\n",
    "We can modify this function to handle follow-up questions as well as multiple tools. \n",
    "\n",
    "We'll call the function `user_agent_multiturn`, which accepts _multiple queries_. \n",
    "\n",
    "For each user and chatbot interaction, we'll print the user's query first. \n",
    "\n",
    "Then, we'll stream `msg.content` and metadata using the `app.stream()` method, which accepts the query and config parameters, with the `stream_mode` set to `\"messages\"`. \n",
    "\n",
    "For each message, we'll filter out human messages to return just the chatbot's responses, before concatenating and printing the responses. \n",
    "\n",
    "Finally, we'll add a new line to keep responses separated. To use this function, we'll pass our queries as a list called `\"queries\"`, where every second question is a follow-up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: What happened on the 12 April 1961?\n",
      "Agent: On April 12, 1961, one of the most significant events in space exploration occurred: Soviet cosmonaut Yuri Gagarin became the first human to travel into space. He orbited the Earth aboard the Vostok 1 spacecraft, marking a major milestone in the Space Race between the United States and the Soviet Union. This achievement not only showcased the capabilities of Soviet space technology but also had profound implications for international politics and the future of space exploration. Gagarin's flight lasted approximately 108 minutes and made him an international hero.On April 12, 1961, one of the most significant events in space exploration occurred: Soviet cosmonaut Yuri Gagarin became the first human to travel into space. He orbited the Earth aboard the Vostok 1 spacecraft, marking a major milestone in the Space Race between the United States and the Soviet Union. This achievement not only showcased the capabilities of Soviet space technology but also had profound implications for international politics and the future of space exploration. Gagarin's flight lasted approximately 108 minutes and made him an international hero.On April 12, 1961, a landmark event in space exploration occurred: **Soviet cosmonaut Yuri Gagarin became the first human to travel into space**. He orbited the Earth aboard the Vostok 1 spacecraft, marking a significant milestone in the Space Race between the United States and the Soviet Union. Gagarin's flight lasted approximately 108 minutes, and this achievement showcased Soviet space technology, making him an international hero and having a lasting impact on global politics and the future of space exploration.\n",
      "\n",
      "User: What about 10 December 1948?\n",
      "Agent: On December 10, 1948, an important historical event took place: the United Nations General Assembly adopted the Universal Declaration of Human Rights (UDHR). This milestone document was a response to the atrocities of World War II and aimed to outline fundamental human rights that should be universally protected. The declaration has since become a foundational text for international human rights law and has inspired many subsequent treaties and national laws aimed at protecting individual freedoms and rights around the world.On December 10, 1948, an important historical event took place: the United Nations General Assembly adopted the Universal Declaration of Human Rights (UDHR). This milestone document was a response to the atrocities of World War II and aimed to outline fundamental human rights that should be universally protected. The declaration has since become a foundational text for international human rights law and has inspired many subsequent treaties and national laws aimed at protecting individual freedoms and rights around the world.On December 10, 1948, a significant historical event occurred: the **United Nations General Assembly adopted the Universal Declaration of Human Rights (UDHR)**. This landmark document was in response to the atrocities of World War II and aimed to outline fundamental human rights that should be universally protected. The UDHR has since become a foundational text for international human rights law and has inspired numerous treaties and national laws aimed at protecting individual freedoms and rights worldwide.\n",
      "\n",
      "User: Is `Mr. Owl ate my metal worm?` a palindrome?\n",
      "Agent: The phrase or word 'Mr. Owl ate my metal worm?' is a palindrome.Yes, the phrase \"Mr. Owl ate my metal worm?\" is a palindrome.\n",
      "\n",
      "User: What about `palladium stadium`?\n",
      "Agent: The phrase or word 'palladium stadium' is not a palindrome.No, the phrase \"palladium stadium\" is not a palindrome.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print the user query first for every interaction\n",
    "def user_agent_multiturn(queries):\n",
    "    for query in queries:\n",
    "        print(f\"User: {query}\")\n",
    "\n",
    "        # Stream through messages corresponding to queries, excluding metadata\n",
    "        print(\"Agent: \" + \"\".join(msg.content for msg, metadata in app.stream(\n",
    "            {\"messages\": [HumanMessage(content=query)]}, config, stream_mode=\"messages\")\n",
    "                                  \n",
    "                                  # Filter out the human messages to print agent messages\n",
    "                                  if msg.content and not isinstance(msg, HumanMessage)) + \"\\n\")\n",
    "        \n",
    "queries = [\"What happened on the 12 April 1961?\", \"What about 10 December 1948?\", \"Is `Mr. Owl ate my metal worm?` a palindrome?\", \"What about `palladium stadium`?\"]\n",
    "user_agent_multiturn(queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Full conversation output**\n",
    "\n",
    "We now have a full conversation with different queries answered using different tools, our user and chatbot responses clearly marked, and follow up questions enabled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **What we've learned**\n",
    "\n",
    "Let's take a moment to recap our exciting journey through agentic systems!\n",
    "\n",
    "We started by diving into the essentials of LangChain agents, where we \n",
    "- created ReAct agents, \n",
    "- enhanced them with custom tools, \n",
    "- configured them to answer follow-up questions. \n",
    "- We also learned how LangChain uses reasoning and LLMs to provide detailed natural language responses.\n",
    "\n",
    "Next, we explored building Chatbots with LangGraph, \n",
    "- integrating external APIs so your agents could access external sources of information, such as __Wikipedia__.\n",
    "  \n",
    "We learned how to simplify building these chatbots by defining \n",
    "- graph and agent states, \n",
    "- adding nodes and edges, and \n",
    "- generating chatbot responses. \n",
    "  \n",
    "We then incorporated __memory__ and __conversation__ capabilities, transforming our chatbot into an _intelligent_, _context-aware assistant_.\n",
    "\n",
    "Finally, we experimented with dynamic chatbots, capable of \n",
    "- switching between tools or \n",
    "- making LLM calls based on a user’s querys\n",
    "- We defined multiple tools, \n",
    "- built flexible workflows for function calling, and \n",
    "- organized chatbot outputs with memory that can handle dynamic tool calls \n",
    "- We wrapped up with multi-turn conversations, creating sophisticated chatbots capable of handling substantial workloads, such as answering questions related to a school curriculum.\n",
    "\n",
    "LangChain offers a suite of packages designed to test these systems in real-world settings before putting them into production.\n",
    "\n",
    "LangSmith helps __debug our workflows__ by __evaluating__ agent responses. <br>\n",
    "LangGraph allows __customization__ of agentic workflows. <br> \n",
    "LangGraph Platform supports __agent deployment__. \n",
    "\n",
    "Be sure to explore all of their documentation to build robust agents capable of impressive workloads! \n",
    "\n",
    "- __Documentation__:\n",
    "  - [LangChain products](https://www.langchain.com)\n",
    "  - [LangGraph and LangGraph Platform](https://langchain-ai.github.io/langgraph/concepts/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
