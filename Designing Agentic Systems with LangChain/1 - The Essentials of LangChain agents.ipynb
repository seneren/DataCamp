{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Agents in LangChain**\n",
    "\n",
    "We'll be working with agents and tools:\n",
    "- **Agents**: Autonomous systems that make decisions and take actions\n",
    "- **Tools**: Functions that agents can use to perform specific tasks, such as\n",
    "  - Data query\n",
    "  - Research reports\n",
    "  - Data analysis\n",
    "\n",
    "Our agents will use tools to perform the tasks: \n",
    "- Solve math problems,\n",
    "- Search Wikipedia,\n",
    "- Determine when to swicth between tools and LLMs based on a given task.\n",
    "\n",
    "Combining tools with agents can also improve accuracy in domains like coding and math. <br>\n",
    "LangChain uses specific tools to break problems into smaller steps, reducing errors. For example, we can use a tool to handle to Order Of Operations in math.\n",
    "\n",
    "### **Expanding agents with LangGraph**\n",
    "\n",
    "LangGraph an enhance tool use even further by structuring tasks in workflows called graphs.\n",
    "\n",
    "\n",
    "\n",
    "<div style=\"display: flex;\">\n",
    "    <!-- Left Column -->\n",
    "    <div style=\"width: 25%; padding: 10px;\">\n",
    "    In these graphs, tasks called \"<b>nodes</b>\" are connected by rules called \"<b>edges</b>\". For example, a database query node can link to a document retrieval node, with an edge pointing to which document is retrieved.\n",
    "    </div>\n",
    "    <!-- Right Column -->\n",
    "    <div style=\"width: 48%; padding: 10px;\">\n",
    "        <img src='./images/graph-str.png' width=25%>\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "### **Create a ReAct agent**\n",
    "\n",
    "Now, let's create a basic ReAct agent that does math.\n",
    "\n",
    "- The `tool` module imported from `langchain_core.tools` lets us use custom functions. \n",
    "- `ChatOpenAI` imported from `langchain_openai` enables communication with OpenAI's language models.\n",
    "- The `create_react_agent` module, imported from `langgraph.prebuilt` functions, helps us create a ReAct agent that can reason and use tools. \n",
    "- Finally, the `math` module lets us perform standard math. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown  # For rendering Markdown text in Jupyter Notebooks\n",
    "from langchain_core.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, once our model has been defined, we'll create a ReAct agent by passing the model and a pre-defined tool to the create_react_agent() function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os       # Import the os module to access environment variables for the OpenAI API key\n",
    "api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "# Pre-defined tool\n",
    "@tool\n",
    "def evaluate_expression(expression: str) -> float:\n",
    "    \"\"\"Evaluates a mathematical expression given as a string.\"\"\"\n",
    "    try:\n",
    "        return eval(expression)  # Use eval carefully, only for safe math expressions\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "# List of tools\n",
    "tools = [evaluate_expression]\n",
    "\n",
    "model = ChatOpenAI(api_key=api_key, model = \"gpt-4o-mini\")\n",
    "\n",
    "# Create the agent\n",
    "agent = create_react_agent(model, tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our tool is a basic calculator, we'll define a math query as a string. We'll pass this query, labeled `\"human\"`, to the agent using the `.invoke()` method, storing the output as a response. We'll then use the `.content` attribute to print the last item in `\"messages\"` of `\"response\"` to get the agent's answer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The result of (2 + 8) multiplied by 9 is 90.\n"
     ]
    }
   ],
   "source": [
    "# Create a query\n",
    "query = \"What is (2+8) multiplied by 9?\"\n",
    "\n",
    "# Invoke the agent and print the response\n",
    "response = agent.invoke({\"messages\": [(\"human\", query)]})\n",
    "\n",
    "print(response['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **EXAMPLE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def count_r_in_word(word: str) -> str:\n",
    "    \"\"\"Counts the number of 'r's in a given word and returns a formatted response.\"\"\"\n",
    "    count = word.lower().count('r')\n",
    "    return f\"The word \\\"{word}\\\" contains {count} 'r's\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word \"Strawberry\" contains 3 'r's.\n"
     ]
    }
   ],
   "source": [
    "# Create the agent\n",
    "app = create_react_agent(model=model, tools=[count_r_in_word])\n",
    "\n",
    "# Create a query\n",
    "query = \"How many r's are in the word 'Strawberry'?\"\n",
    "\n",
    "# Invoke the agent and store the response\n",
    "response = app.invoke({\"messages\": [(\"human\", query)]})\n",
    "\n",
    "# Print the agent's response\n",
    "print(response['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Building custom tools**\n",
    "\n",
    "1. We'll start by using a _decorator_ called $ \\text{\\textcolor{green}{@tool}} $ that LangChain uses to recognize custom functions as tools. \n",
    "\n",
    "2. After the decorator, we'll create a function called `rectangle_area` that takes in a _string_ as an input. \n",
    "\n",
    "3. We then include a _docstring_ to describe the function's purpose, specifying that it calculates the area of a rectangle given the lengths of two sides, `a` and `b`. \n",
    "\n",
    "4. Inside the function, we `split` the input string extracted from the query into the two values representing sides a and b. \n",
    "\n",
    "5. To multiply the sides, we _strip_ any whitespace around the string inputs using Python's `.strip()` method and then convert each string to a float. \n",
    "\n",
    "6. We then multiply sides a and b together to calculate and return the area of the rectangle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def rectangle_area(input: str) -> float:\n",
    "    \"\"\"Calculate the area of a rectangle given its lengths of sides a and b.\"\"\"\n",
    "    sides = input.split(',')\n",
    "    a = float(sides[0].strip())\n",
    "    b = float(sides[1].strip())\n",
    "    return a * b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our tool, let's make sure LangChain can access it by passing it within a list called `\"tools\"`. Although we're only using one tool here, it's possible to list more, depending on our workflow. Then, we'll create a variable called `\"query\"` that accepts a question from the user in the form of natural language. \n",
    "\n",
    "We'll then create our ReAct agent called `app`, passing in the model, and the tool we just built.\n",
    "\n",
    "To test that the agent works, we'll invoke the agent we just created, passing in the `query` we defined and then print the agent's `response` by identifying the last item in `\"messages\"` using the `.content` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area of the rectangle with sides 5 and 7 is 35 square units.\n"
     ]
    }
   ],
   "source": [
    "# Define the tools that the agent will use\n",
    "tools = [rectangle_area]\n",
    "\n",
    "# Create a query using natural language\n",
    "query=\"What is the area of a rectangle with sides 5 and 7?\"\n",
    "\n",
    "# Pass in the tool and invoke the agent\n",
    "app = create_react_agent(model, tools)\n",
    "\n",
    "# Invoke the agent and print the response\n",
    "response = app.invoke({\"messages\": [(\"human\", query)]})\n",
    "\n",
    "print(response['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LangChain also has an extensive library of pre-built tools for solving many other problems such as \n",
    "- database querying, \n",
    "- web scraping, and \n",
    "- image generation, \n",
    "\n",
    "which can be incorporated by referencing [LangChain's API guide](https://python.langchain.com/docs/integrations/tools/). We can also reference [LangChain's Custom tool guide](https://python.langchain.com/docs/how_to/custom_tools/) for using tool decorators to build other custom tools!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Conversation with a ReAct agent**\n",
    "\n",
    "So far, we've just been printing the agent's outputs. It's also useful to know that our agent is responding correctly by printing both the user's query as well as the response.\n",
    "\n",
    "### **Conversation history**\n",
    "\n",
    "To set up our conversation history, we'll import the `HumanMessage` and `AIMessage` modules from `langchain_core.messages`.\n",
    "\n",
    "Then, wel'll set up a variable called `message_history` that will store all of our messages.\n",
    "\n",
    "Next, we'll defina new query that will ask a new question without providing any additional contextual information. \n",
    "(Here, we want know the area if a new rectangle with different dimensions)\n",
    "\n",
    "Next,  we'll invoke the app object again, this time passing both message histpry anf new query to the agent within a dictionary.\n",
    "\n",
    "We'll then filter out only the relevant messages from the agent's response. Here, we'll use a list comprehension to select both HumanMessage and AIMessage instances that contain actual content. When applied to `msg.content`, the `.strip()` method removes any trailing whitespaces.\n",
    "\n",
    "Finally, we'll format and print the conversation extracted from `msg.content`, with each message labeled using its proper class name. The `\"user_input\"` is our new query, while the `\"agent_output\"` will print the full conversation and repeat the agent's most recent output, which uis useful for debugging.\n",
    "\n",
    "Let's see if we can produce the elements we need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'user_input': 'What about one with sides 4 and 3?', 'agent_output': ['HumanMessage: What is the area of a rectangle with sides 5 and 7?', 'AIMessage: The area of the rectangle with sides 5 and 7 is 35 square units.', 'HumanMessage: What about one with sides 4 and 3?', 'AIMessage: The area of the rectangle with sides 4 and 3 is 12 square units.']}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "message_history = response[\"messages\"]\n",
    "\n",
    "new_query = \"What about one with sides 4 and 3?\"\n",
    "\n",
    "# Invoke the app with the full message history\n",
    "messages = app.invoke({\"messages\": message_history + [(\"human\", new_query)]})\n",
    "\n",
    "# Extract the human and AI messages\n",
    "filtered_messages = [msg for msg in messages[\"messages\"] if isinstance(msg,(HumanMessage, AIMessage)) and msg.content.strip()]\n",
    "\n",
    "# Format and print the final result\n",
    "print({\n",
    "    \"user_input\": new_query,\n",
    "    \"agent_output\": [f\"{msg.__class__.__name__}: {msg.content}\" for msg in filtered_messages]\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have our new query labeled `\"user_input\"`. Then, we have our `agent_output` listing the full conversation with labeled human and AI messages. \n",
    "\n",
    "When we ask the agent to list the last message, we have our most recent query and answer. Everything is in good shape!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'user_input': 'What about one with sides 4 and 3?', 'agent_output': 'AIMessage: The area of the rectangle with sides 4 and 3 is 12 square units.'}\n"
     ]
    }
   ],
   "source": [
    "# Replace the existing print block at the end with this:\n",
    "print({\n",
    "    \"user_input\": new_query,\n",
    "    \"agent_output\": f\"{messages['messages'][-1].__class__.__name__}: {messages['messages'][-1].content}\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full functional code is below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'user_input': 'What about one with sides 4 and 3?', 'agent_output': ['HumanMessage: What is the area of a rectangle with sides 5 and 7?', 'AIMessage: The area of the rectangle with sides 5 and 7 is 35 square units.', 'HumanMessage: What about one with sides 4 and 3?', 'AIMessage: The area of the rectangle with sides 4 and 3 is 12 square units.']}\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "from langchain_core.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "import math\n",
    "import os \n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "@tool\n",
    "def rectangle_area(input: str) -> float:\n",
    "    \"\"\"Calculate the area of a rectangle given its lengths of sides a and b.\"\"\"\n",
    "    sides = input.split(',')\n",
    "    a = float(sides[0].strip())\n",
    "    b = float(sides[1].strip())\n",
    "    return a * b\n",
    "\n",
    "model = ChatOpenAI(api_key=api_key, model = \"gpt-4o-mini\")\n",
    "\n",
    "# Define the tools that the agent will use\n",
    "tools = [rectangle_area]\n",
    "\n",
    "# Create a query using natural language\n",
    "query = \"What is the area of a rectangle with sides 5 and 7?\"\n",
    "\n",
    "# Pass in the tool and invoke the agent\n",
    "app = create_react_agent(model, tools)\n",
    "\n",
    "# Invoke the agent and print the response\n",
    "response = app.invoke({\"messages\": [(\"human\", query)]})\n",
    "\n",
    "# Store message history from the first conversation\n",
    "message_history = response[\"messages\"]\n",
    "\n",
    "# Create a new query\n",
    "new_query = \"What about one with sides 4 and 3?\"\n",
    "\n",
    "# Invoke the app with the full message history\n",
    "messages = app.invoke({\"messages\": message_history + [(\"human\", new_query)]})\n",
    "\n",
    "# Extract the human and AI messages\n",
    "filtered_messages = [msg for msg in messages[\"messages\"] if isinstance(msg,(HumanMessage, AIMessage)) and msg.content.strip()]\n",
    "\n",
    "# Format and print the final result\n",
    "print({\n",
    "    \"user_input\": new_query,\n",
    "    \"agent_output\": [f\"{msg.__class__.__name__}: {msg.content}\" for msg in filtered_messages]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
