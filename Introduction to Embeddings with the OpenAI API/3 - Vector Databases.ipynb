{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Vector databases for embedding systems**\n",
    "\n",
    "<img src = './images/limits-of-current-approach.png' width=50% height=50%>\n",
    "\n",
    "So far, we've created embeddings using the OpenAI API and stored them in-memory. \n",
    "\n",
    "* Loading all the embeddings into memory (1536 floats ~ 13kB/embedding), which becomes impractical to load for 100,000s or millions of embeddings. \n",
    "* Recalculated these embeddings with every query rather than storing them for later use. \n",
    "* We computed cosine distances for every embedded document and sorted the results, which are both slow processes that scale linearly. \n",
    "\n",
    "To enable embeddings applications with larger datasets in production, we'll need a better solution: __vector databases__!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Vector databases**\n",
    "\n",
    "Here's a typical embeddings application: \n",
    "\n",
    "<img src = './images/embedding-app-arch.png' width=50% height=50%>\n",
    "\n",
    "* Embedded documents are _stored_ and _queried_ from the __vector database__\n",
    "\n",
    "- The documents to query are embedded and stored in the vector database. \n",
    "- A query is sent from the application interface, embedded, and used to query the embeddings in the database. This query can be a semantic search query or data to base recommendations on. \n",
    "- Finally, these results are returned by to the user via the application interface. \n",
    "\n",
    "Because the embedded documents are stored in the vector database, they don't have to created with each query or stored in-memory. Additionally, due to the architecture of the database, the similarity calculation is computed much more efficiently.\n",
    "\n",
    "### **NoSQL databases vs SQL databases**\n",
    "\n",
    "The majority of vector databases are what's called NoSQL databases, which contrasts conventional databases.\n",
    "\n",
    "<div style=\"display: flex;\">\n",
    "    <div style=\"flex: 50%; padding: 5px; border-right: 2px solid DodgerBlue;\">\n",
    "        **NoSQL Database**  <br>\n",
    "        <div style=\"text-align: center;\">\n",
    "            <img src='./images/nosql-db.png' width=75% height=80%>\n",
    "        </div>\n",
    "        NoSQL databases don't use tables\n",
    "        <ul>\n",
    "            <li>More flexible structure that allows for <i>faster querying</i></li>\n",
    "            <li>Three examples are shown above: including key:value, document, and graph databases</li>\n",
    "        </ul>\n",
    "    </div>\n",
    "    <div style=\"flex: 50%; padding: 5px;\">\n",
    "        **SQL/Relational Database**  <br>\n",
    "        <div style=\"text-align: center;\">\n",
    "            <img src='./images/sql-db.png' width=75% height=80%>\n",
    "        </div>\n",
    "        <ul>\n",
    "            <li>Structured data into tables, rows. and columns</li>\n",
    "        </ul>\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "### **The vector database landscape**\n",
    "\n",
    "<img src='./images/vector-db-options.png' width=60% height=60%>\n",
    "\n",
    "When deciding which database solution to go with, there are several factors to consider.\n",
    "\n",
    "### **Which solution is best?**\n",
    "\n",
    "<div style=\"display: flex;\">\n",
    "    <div style=\"flex: 50%; padding: 5px; border-right: 2px solid DodgerBlue;\">\n",
    "        <ul>\n",
    "           <li><b>Database management</b></li>\n",
    "           <ul>\n",
    "               <li>Managed &#x2192; more expensive but lowers workload.</li>\n",
    "               <li>Self-managed &#x2192; cheaper but requires time and expertise\n",
    "            </ul>\n",
    "        </ul>\n",
    "        <ul>\n",
    "            <li><b>Open source or commercial?</b></li>\n",
    "            <ul>\n",
    "               <li>Open source &#x2192; flexible and cost-effective if budgets are tight</li>\n",
    "               <li>Commercial &#x2192; offers better support, more advanced features, and compliance</li>\n",
    "        </ul>\n",
    "    </div>\n",
    "    <div style=\"flex: 50%; padding: 5px;\">\n",
    "        <ul>\n",
    "            <li><b>Data models</b>: does the type of data lend itself to a particular database type?</li>\n",
    "            <li><b> Specific features</b>: does your use case depend on specific functionality, like embedding and storung both text and images for a multi-modal application?</li>\n",
    "        </ul>\n",
    "        In this course, we'll be using Chroma, as it's open-source and quick to set up.\n",
    "        <div style=\"text-align: center;\">\n",
    "            <img src='./images/chroma.png' width=50% height=50%>\n",
    "        </div>\n",
    "    </div>\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Creating vector databases with ChromaDB**\n",
    "\n",
    "ChromaDB has two modes:\n",
    "\n",
    "* __Local mode__:\n",
    "  * Great for development and prototyping. Everything runs on our local machine, inside Python.\n",
    "* __Client/Server mode __:\n",
    "  *  Made for production. Requires running a separate process for the chroma server.\n",
    "\n",
    "We'll be using the local mode.\n",
    "\n",
    "### **Connecting to the database**\n",
    "\n",
    "In order to connect and query the database, we need to create a client: We import the chroma and create a persistend cliend by calling the `PersistentClient()` function. Persisten client saves the database files to disk at the path specified.\n",
    "\n",
    "```python\n",
    "import chromadb\n",
    "\n",
    "client = chroma.PersistentClient(path='/path/to/save/to')\n",
    "```\n",
    "\n",
    "### **Creating a collection**\n",
    "\n",
    "To add embeddings to the database, we must first create a collection. Collections are analogous to tables, where we can create as many as we want to store our data. To create the collection, we use the `.create_collection()` method. When creating a collection, we need to pass the name of our collection, which is used as a reference, and the function for creating the embeddings; here, we specify the OpenAI embedding function and API key.\n",
    "\n",
    "```python\n",
    "from chromadb.utils.embedding_functions import OpenAIEmbeddingFunction\n",
    "\n",
    "collection = client.create_collection(\n",
    "    name=\"my_collection\",\n",
    "    embedding_function=OpenAIEmbeddingFunction(\n",
    "        model_name=\"text-embedding-3-small\",\n",
    "        api_key=\"<OPENAI_API_KEY>\"\n",
    "    )\n",
    ")\n",
    "```\n",
    "\n",
    "### **Inspecting the collection**\n",
    "\n",
    "The `list_collections` method lists all of the collections in the database, so we can verify our collection was created.\n",
    "\n",
    "```python\n",
    "client.list_collections()\n",
    "```\n",
    "\n",
    "Output: <br>\n",
    "`[Collection(name=my_collection)]`\n",
    "\n",
    "### **Inserting embeddings**\n",
    "\n",
    "We are now ready to add embeddings into the collection. We can do so with the `collection.add` method.\n",
    "\n",
    "* IDs must be provided\n",
    "* Embeddings will be created by the collection.\n",
    "\n",
    "Since the collection is already aware of the embedding function, it will embed the source texts automatically using the function specified. Most of the time, we'll insert multiple documents at once, which we can do by passing multiple ids and documents.\n",
    "\n",
    "**Single Document**\n",
    "\n",
    "```python\n",
    "collection.add(ids=['my-doc'], documents=['This is a the source text'])\n",
    "```\n",
    "\n",
    "**Multiple Documents**\n",
    "\n",
    "```python\n",
    "collection.add(ids=['my-doc1', 'my-doc2'], documents=['This is document 1', 'This is document 2'])\n",
    "```\n",
    "\n",
    "### **Inspecting the collection**\n",
    "\n",
    "After inserting documents, we can inspect the collection with twi methods\n",
    "\n",
    "1. __`collection.count()` method__: Returns the total number of documents in the collection.\n",
    "\n",
    "```python\n",
    "collection.count()\n",
    "```\n",
    "Output: <br>\n",
    "`3`\n",
    "\n",
    "2. __`collection.peek()` method__: Returns the first __10__ items in the collection.__\n",
    "\n",
    "```python\n",
    "collection.peek()\n",
    "```\n",
    "Output: <br>\n",
    "<img src='./images/collection-peek.png' width=50% height=50%>\n",
    "\n",
    "We can also retrieve particular items by their ID using the `.get()` method.\n",
    "\n",
    "```python\n",
    "collection.get(ids=['s59'])\n",
    "```\n",
    "Output: <br>\n",
    "<img src='./images/retrieve-item.png' width=50% height=50%>\n",
    "\n",
    "### **Netflix Dataset**\n",
    "In the following exercises, we';; insert a dataset of Netflix titles into a Chroma dataase. for each title, we'll embed a source text including the title, description, and categories. \n",
    "\n",
    "<img src='./images/netflix-dataset.png' width=50% height=50%>\n",
    "\n",
    "While this is not a massive dataset, we must not forget that each of these texts is going to be sent to the OpenAI embedding endpoint and therefore cost money. Before inserting a sizable dataset into a collection, it's important to get an idea of the cost.\n",
    "\n",
    "### **Cost Estimation**\n",
    "\n",
    "* Embedding model (`text-embedding-3-small`) costs $0.00002/1k tokens ($0.02/1M tokens)\n",
    "\n",
    "OpenAI provides the cost per thousand tokens on their model pricing page, which means we can find the total cost\n",
    "\n",
    "`cost = 0.00002 * len(tokens)/1000`\n",
    "\n",
    "We can count tokens with `tiktoken` library. (to install `pip install tiktoken`)\n",
    "\n",
    "### **Estimating embedding cost**\n",
    "\n",
    "Tiktoken can convert any text into tokens. \n",
    "\n",
    "First, we use the `encoding_for_model` function to get a token encoder for the embedding model we're using. To calculate the total number of tokens, we use the following code. This reads: for each text in documents, encode it using the encoder and take the `length` to obtain the number of tokens in the text. Finally, `sum` the results. This code is much more concise and efficient than looping through the documents.\n",
    "\n",
    "Finally, we calculate the price by multiplying `total_tokens` by `cost_per_1k_tokens` over `1000`, and print the result.\n",
    "\n",
    "```python\n",
    "import tiktoken\n",
    "\n",
    "enc = tiktoken.encoding_for_model('text-embeddding-3-small')\n",
    "\n",
    "total_tokens = sum(len(end.encode(text)) for text in documents)\n",
    "\n",
    "cost_per_1k_tokens = 0.00002\n",
    "\n",
    "print('Total tokens:\", total_tokens)\n",
    "print('Cost:', cost_per_1k_tokens * total_tokens/1000)\n",
    "```\n",
    "\n",
    "Then it would give:\n",
    "```\n",
    "Total tokens: 444463\n",
    "Cost: 0.0888926\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example\n",
    "\n",
    "**Instructions**\n",
    "\n",
    "* Create a persistent client to save the database files to disk; you can leave out the file path for these exercises.\n",
    "* Create a database collection called `netflix_titles` that uses the OpenAI embedding function.\n",
    "* List all of the collections in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['netflix_titles']\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "from chromadb.utils.embedding_functions import OpenAIEmbeddingFunction\n",
    "import os                               # to get the current working directory\n",
    "from dotenv import load_dotenv          # to load the .env file\n",
    "\n",
    "# Load the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get the API key from the .env file\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Create a persistant client\n",
    "client = chromadb.PersistentClient(path=\"./datasets/\")\n",
    "\n",
    "# Create a netflix_title collection using the OpenAI Embedding function\n",
    "collection = client.create_collection(\n",
    "    name=\"netflix_titles\",\n",
    "    embedding_function=OpenAIEmbeddingFunction(model_name=\"text-embedding-3-small\", api_key=\"<OPENAI_API_TOKEN>\")\n",
    ")\n",
    "\n",
    "# List the collections\n",
    "print(client.list_collections())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've created a database and collection to store the Netflix films and TV shows, we can begin embedding data.\n",
    "\n",
    "Before embedding a large dataset, it's important to do a cost estimate to ensure you don't go over any budget restraints. Because OpenAI models are priced by number of tokens inputted, we'll use OpenAI's tiktoken library to count the number of tokens and convert them into a dollar cost.\n",
    "\n",
    "You've been provided with document texts as `documents`, which has been extracted from `netflix_titles_1000.csv`. Here is the first document from `documents`:\n",
    "```\n",
    "Title: Dick Johnson Is Dead (Movie)\n",
    "Description: As her father nears the end of his life, filmmaker Kirsten Johnson stages his death in inventive and comical ways to help them both face the inevitable.\n",
    "Categories: Documentaries\n",
    "```\n",
    "\n",
    "For later use, you've also been provided with document IDs.\n",
    "\n",
    "You'll now iterate over the list, encode each document, and count the total number of tokens. Finally, you'll use the model's pricing to convert this into a cost.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 documents:\n",
      "Title: Dick Johnson Is Dead (Movie)\n",
      "Description: As her father nears the end of his life, filmmaker Kirsten Johnson stages his death in inventive and comical ways to help them both face the inevitable.\n",
      "Categories: Documentaries\n",
      "\n",
      "Title: Blood & Water (TV Show)\n",
      "Description: After crossing paths at a party, a Cape Town teen sets out to prove whether a private-school swimming star is her sister who was abducted at birth.\n",
      "Categories: International TV Shows, TV Dramas, TV Mysteries\n",
      "\n",
      "Title: Ganglands (TV Show)\n",
      "Description: To protect his family from a powerful drug lord, skilled thief Mehdi and his expert team of robbers are pulled into a violent and deadly turf war.\n",
      "Categories: Crime TV Shows, International TV Shows, TV Action & Adventure\n",
      "\n",
      "Title: Jailbirds New Orleans (TV Show)\n",
      "Description: Feuds, flirtations and toilet talk go down among the incarcerated women at the Orleans Justice Center in New Orleans on this gritty reality series.\n",
      "Categories: Docuseries, Reality TV\n",
      "\n",
      "Title: Kota Factory (TV Show)\n",
      "Description: In a city of coaching centers known to train India’s finest collegiate minds, an earnest but unexceptional student and his friends navigate campus life.\n",
      "Categories: International TV Shows, Romantic TV Shows, TV Comedies\n",
      "\n",
      "Last 5 documents:\n",
      "Title: Zodiac (Movie)\n",
      "Description: A political cartoonist, a crime reporter and a pair of cops investigate San Francisco's infamous Zodiac Killer in this thriller based on a true story.\n",
      "Categories: Cult Movies, Dramas, Thrillers\n",
      "\n",
      "Title: Zombie Dumb (TV Show)\n",
      "Description: While living alone in a spooky town, a young girl befriends a motley crew of zombie children with diverse personalities.\n",
      "Categories: Kids' TV, Korean TV Shows, TV Comedies\n",
      "\n",
      "Title: Zombieland (Movie)\n",
      "Description: Looking to survive in a world taken over by zombies, a dorky college student teams with an urban roughneck and a pair of grifter sisters.\n",
      "Categories: Comedies, Horror Movies\n",
      "\n",
      "Title: Zoom (Movie)\n",
      "Description: Dragged from civilian life, a former superhero must train a new crop of youthful saviors when the military preps for an attack by a familiar villain.\n",
      "Categories: Children & Family Movies, Comedies\n",
      "\n",
      "Title: Zubaan (Movie)\n",
      "Description: A scrappy but poor boy worms his way into a tycoon's dysfunctional family, while facing his fear of music and the truth about his past.\n",
      "Categories: Dramas, International Movies, Music & Musicals\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "ids = []\n",
    "documents = []\n",
    "\n",
    "with open('./datasets/netflix_titles.csv') as csvfile:\n",
    "  reader = csv.DictReader(csvfile)\n",
    "  for i, row in enumerate(reader):\n",
    "    ids.append(row['show_id'])\n",
    "    text = f\"Title: {row['title']} ({row['type']})\\nDescription: {row['description']}\\nCategories: {row['listed_in']}\"\n",
    "    documents.append(text)\n",
    "\n",
    "# Print first 5 and last 5 documents\n",
    "print(\"First 5 documents:\")\n",
    "for doc in documents[:5]:\n",
    "    print(doc)\n",
    "    print()\n",
    "\n",
    "print(\"Last 5 documents:\")\n",
    "for doc in documents[-5:]:\n",
    "    print(doc)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens: 444463\n",
      "Cost: 0.00888926\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "# Load the encoder for the OpenAI text-embedding-3-small model\n",
    "enc = tiktoken.encoding_for_model(\"text-embedding-3-small\")\n",
    "\n",
    "# Encode each text in documents and calculate the total tokens\n",
    "total_tokens = sum(len(enc.encode(text)) for text in documents)\n",
    "\n",
    "cost_per_1k_tokens = 0.00002\n",
    "\n",
    "# Display number of tokens and cost\n",
    "print('Total tokens:', total_tokens)\n",
    "print('Cost:', cost_per_1k_tokens * total_tokens/1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That means, for each request, the cost will be $0.00888926.\n",
    "\n",
    "Time to add those Netflix films and TV shows to your collection.\n",
    "\n",
    "__Instructions__\n",
    "\n",
    "* Recreate your `netflix_titles` collection.\n",
    "* Add the documents and their IDs to the collection.\n",
    "* Print the number of documents in `collection` and the first ten items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of documents: 8807\n",
      "First ten documents: {'ids': ['s1', 's2', 's3', 's4', 's5', 's6', 's7', 's8', 's9', 's10'], 'embeddings': array([[ 0.02242333,  0.05174443, -0.02444355, ...,  0.02265772,\n",
      "        -0.00398463, -0.02413103],\n",
      "       [-0.00256908,  0.09567138, -0.04806154, ...,  0.01961534,\n",
      "         0.03606874, -0.04447048],\n",
      "       [-0.015072  ,  0.05057291, -0.04685031, ..., -0.00316648,\n",
      "         0.00111224, -0.04591966],\n",
      "       ...,\n",
      "       [-0.02682706,  0.05365412, -0.02775045, ...,  0.03700871,\n",
      "        -0.02228298, -0.02446997],\n",
      "       [ 0.01401989,  0.0206609 , -0.0120415 , ...,  0.01189178,\n",
      "         0.01038392, -0.04914984],\n",
      "       [ 0.00980071,  0.07244343, -0.03348716, ...,  0.01767378,\n",
      "         0.02326618, -0.0031016 ]]), 'documents': ['Title: Dick Johnson Is Dead (Movie)\\nDescription: As her father nears the end of his life, filmmaker Kirsten Johnson stages his death in inventive and comical ways to help them both face the inevitable.\\nCategories: Documentaries', 'Title: Blood & Water (TV Show)\\nDescription: After crossing paths at a party, a Cape Town teen sets out to prove whether a private-school swimming star is her sister who was abducted at birth.\\nCategories: International TV Shows, TV Dramas, TV Mysteries', 'Title: Ganglands (TV Show)\\nDescription: To protect his family from a powerful drug lord, skilled thief Mehdi and his expert team of robbers are pulled into a violent and deadly turf war.\\nCategories: Crime TV Shows, International TV Shows, TV Action & Adventure', 'Title: Jailbirds New Orleans (TV Show)\\nDescription: Feuds, flirtations and toilet talk go down among the incarcerated women at the Orleans Justice Center in New Orleans on this gritty reality series.\\nCategories: Docuseries, Reality TV', 'Title: Kota Factory (TV Show)\\nDescription: In a city of coaching centers known to train India’s finest collegiate minds, an earnest but unexceptional student and his friends navigate campus life.\\nCategories: International TV Shows, Romantic TV Shows, TV Comedies', 'Title: Midnight Mass (TV Show)\\nDescription: The arrival of a charismatic young priest brings glorious miracles, ominous mysteries and renewed religious fervor to a dying town desperate to believe.\\nCategories: TV Dramas, TV Horror, TV Mysteries', \"Title: My Little Pony: A New Generation (Movie)\\nDescription: Equestria's divided. But a bright-eyed hero believes Earth Ponies, Pegasi and Unicorns should be pals — and, hoof to heart, she’s determined to prove it.\\nCategories: Children & Family Movies\", 'Title: Sankofa (Movie)\\nDescription: On a photo shoot in Ghana, an American model slips back in time, becomes enslaved on a plantation and bears witness to the agony of her ancestral past.\\nCategories: Dramas, Independent Movies, International Movies', \"Title: The Great British Baking Show (TV Show)\\nDescription: A talented batch of amateur bakers face off in a 10-week competition, whipping up their best dishes in the hopes of being named the U.K.'s best.\\nCategories: British TV Shows, Reality TV\", \"Title: The Starling (Movie)\\nDescription: A woman adjusting to life after a loss contends with a feisty bird that's taken over her garden — and a husband who's struggling to find a way forward.\\nCategories: Comedies, Dramas\"], 'uris': None, 'data': None, 'metadatas': [None, None, None, None, None, None, None, None, None, None], 'included': [<IncludeEnum.embeddings: 'embeddings'>, <IncludeEnum.documents: 'documents'>, <IncludeEnum.metadatas: 'metadatas'>]}\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import chromadb\n",
    "from chromadb.utils.embedding_functions import OpenAIEmbeddingFunction\n",
    "import os                               # to get the current working directory\n",
    "from dotenv import load_dotenv          # to load the .env file\n",
    "\n",
    "# Load the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get the API key from the .env file\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Create a persistant client\n",
    "client = chromadb.PersistentClient(path=\"./datasets/\")\n",
    "\n",
    "ids = []\n",
    "documents = []\n",
    "\n",
    "with open('./datasets/netflix_titles.csv') as csvfile:\n",
    "  reader = csv.DictReader(csvfile)\n",
    "  for i, row in enumerate(reader):\n",
    "    ids.append(row['show_id'])\n",
    "    text = f\"Title: {row['title']} ({row['type']})\\nDescription: {row['description']}\\nCategories: {row['listed_in']}\"\n",
    "    documents.append(text)\n",
    "\n",
    "# Recreate the netflix_titles collection\n",
    "collection = client.create_collection(\n",
    "  name=\"netflix_titles\",\n",
    "  embedding_function=OpenAIEmbeddingFunction(\n",
    "    model_name=\"text-embedding-3-small\", \n",
    "    api_key=api_key)\n",
    ")\n",
    "\n",
    "\"\"\"The following code line may not work because since file is big, it tries to add too many documents at once. \n",
    "Splitting the documents into smaller batches will work.\"\"\"\n",
    "# collection.add(ids=ids, documents=documents)\n",
    "\n",
    "# Add documents in batches of 100\n",
    "batch_size = 1000\n",
    "for i in range(0, len(documents), batch_size):\n",
    "    batch_ids = ids[i:i + batch_size]\n",
    "    batch_docs = documents[i:i + batch_size]\n",
    "    collection.add(ids=batch_ids, documents=batch_docs)\n",
    "\n",
    "\n",
    "# Print the collection size and first ten items\n",
    "print(f\"No. of documents: {collection.count()}\")\n",
    "print(f\"First ten documents: {collection.peek()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Querying and updating the database**\n",
    "\n",
    "### **Querying the database**\n",
    "\n",
    "Similar to what we did manually in the previous chapter, we'll build a semantic search application, but this time, using a vector database. The approach is exactly the same: we have a query string and we want to find similar titles in our collection. \n",
    "\n",
    "Previously, we had to embed the query string to get a query vector, which was used to find similar embeddings in the dataset:\n",
    "\n",
    "<img src=\"./images/previously.png\" width=50% height=50%>\n",
    "\n",
    "With Chroma, we'll let the collection do the embedding, so we can pass our query string directly and Chroma will take care of creating the embedding and performing the search:\n",
    "\n",
    "<img src=\"./images/now-chroma.png\" width=50% height=50%>\n",
    "\n",
    "First, we need to retrieve our collection, which we can do with `client.get_collection()`, specifying the name of the collection to retrieve. Recall that when we created the collection, we specified the embedding function to use, and it's also really important to specify the same function when retrieving the collection. This way, Chroma will use the same embedding function to create the _query vector_.\n",
    "\n",
    "```python\n",
    "from chromadb.utils.embedding_function import OpenAiEmbeddingFunction\n",
    "\n",
    "collection = client.get_collection(\n",
    "    name='netflix_titles_test1',\n",
    "    embedding_function= OpenAIEmbeddingFunction(\n",
    "        api_key=\"<OPENAI_API_KEY>\"\n",
    "    )\n",
    ")\n",
    "```\n",
    "\n",
    "### **Querying the collection**\n",
    "\n",
    "To query the collection, we call collection.query, passing our query string to `query_texts`. Note that this parameter is _plural_, so even if we have a single query string, we pass a list. To specify how many items to retrieve, we can use the `n_results` parameter. \n",
    "\n",
    "```python\n",
    "result = collection.query(\n",
    "    query_texts=[\"movies where people sing a lot\"],\n",
    "    n_results=3\n",
    ")\n",
    "```\n",
    "\n",
    "Let's run the code below and see the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  'ids': [['s1995', 's2213', 's4068']],\n",
      "  'embeddings': None,\n",
      "  'documents': [\n",
      "    'Title: Sing On! (TV Show)\n",
      "Description: In this fun, fast-paced music contest hosted by Tituss Burgess, players sing their hearts out and try to hit the right notes to win up to $60,000.\n",
      "Categories: Reality TV',\n",
      "    'Title: Sing On! Spain (TV Show)\n",
      "Description: In this fast-paced, high-energy karaoke competition, singers from all walks of life battle it out for up to 30,000 euros!\n",
      "Categories: International TV Shows, Reality TV, Spanish-Language TV Shows',\n",
      "    'Title: Quién te cantará (Movie)\n",
      "Description: When a near-drowning leaves a famous singer from the '90s with amnesia, she hires a karaoke singer who can imitate her to prep her for a comeback tour.\n",
      "Categories: Dramas, Independent Movies, International Movies',\n",
      "  ],\n",
      "  'uris': None,\n",
      "  'data': None,\n",
      "  'metadatas': [[None, None, None]],\n",
      "  'distances': [[1.0086209774017334, 1.0409395694732666, 1.0469950437545776]],\n",
      "  'included': [<IncludeEnum.distances: 'distances'>, <IncludeEnum.documents: 'documents'>, <IncludeEnum.metadatas: 'metadatas'>],\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from chromadb.utils.embedding_functions import OpenAIEmbeddingFunction\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get API key from environment variable\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "collection = client.get_collection(\n",
    "    name='netflix_titles',\n",
    "    embedding_function= OpenAIEmbeddingFunction(\n",
    "        model_name=\"text-embedding-3-small\",\n",
    "        api_key=api_key\n",
    "    )\n",
    ")\n",
    "\n",
    "result = collection.query(\n",
    "    query_texts=[\"movies where people sing a lot\"],\n",
    "    n_results=3\n",
    ")\n",
    "\n",
    "\"\"\"To display the output in a more readable format,\n",
    "we can format the dictionary output with each key-value pair on a new line as follows:\"\"\"\n",
    "\"\"\"If you want to see the raw result, you can do print(result)\"\"\"\n",
    "\n",
    "# Format the dictionary output with each key-value pair on a new line\n",
    "formatted_output = \"{\\n\"\n",
    "for key, value in result.items():\n",
    "    if key == 'documents':\n",
    "        # Format each document on a new line\n",
    "        formatted_output += f\"  '{key}': [\\n\"\n",
    "        for doc in value[0]:\n",
    "            formatted_output += f\"    '{doc}',\\n\"\n",
    "        formatted_output += \"  ],\\n\"\n",
    "    else:\n",
    "        formatted_output += f\"  '{key}': {value},\\n\"\n",
    "formatted_output += \"}\"\n",
    "\n",
    "print(formatted_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Query Result (dict)**\n",
    "\n",
    "let's break the output down:\n",
    "\n",
    "`query()` returns a dictionary with the following keys:\n",
    "- `ids`: a list of the IDs of the documents that were returned\n",
    "- `embeddings`: The embeddings of the returned items\n",
    "- `documents`: The source texts if the returned items\n",
    "- `metadatas`: The metadatas of the returned items\n",
    "- `distances`: The distances between the query and the returned items\n",
    "- `uris`: The URIs of the returned items\n",
    "- `data`: The data of the returned items\n",
    "- `included`: The list of lists of included items, excluding `uris` and `data`.\n",
    "\n",
    "\n",
    "The embeddings entry is emty, simply because Chroma doesn't return them by default. Also, each of these entries has the same format; let's look at ids\n",
    "\n",
    "### **Query results (list of lists)**\n",
    "\n",
    "ids contains a list of lists. The reason for this is that the query method accepts a list of query texts, even though we used one query text. - meaning we could use multiple query texts. So, the result follow the same structure:\n",
    "\n",
    "* First list corresponds to the first query_text\n",
    "* Multiple query texts will return multiple lists - If we had multiple query texts, we would get back as many lists.\n",
    "\n",
    " In this list, we find a format similar to the parameters of the add() method: the first id corresponds to the first document, metadatas, and distances:\n",
    "\n",
    " <img src='./images/query_result.png' width=50% height=50%>\n",
    "\n",
    "\n",
    "### **Updating a collection**\n",
    "\n",
    "Items in a collection can be updated with the `update` method. The syntax is similar to `collection.add()`; in this example, we'll update the texts for items `id-1` and `id-2`. \n",
    "\n",
    "* Include _only_ the fields to update, other fields will be unchanged\n",
    "* Collection will automatically create embeddings\n",
    "\n",
    "```python\n",
    "collecton.update(\n",
    "    ids=[\"id-1\", \"id-2\"],\n",
    "    documents=[\"New document 1\", \"New document 2\"],\n",
    ")\n",
    "```\n",
    "\n",
    "Alternatively,  if we're not sure if the IDs are already present in the table, use the `upsert` method. `upsert` will add the IDs to the collection if they aren't present, and update them if they are - a combination of the update and add methods.\n",
    "\n",
    "```python\n",
    "collection.upsert(\n",
    "    ids=[\"id-1\", \"id-2\"],\n",
    "    documents=[\"New document 1\", \"New document 2\"],\n",
    ")\n",
    "```\n",
    "\n",
    "### **Deleting**\n",
    "\n",
    "__Delete items from a collection__\n",
    "\n",
    "```python\n",
    "collection.delete(ids=[\"id-1\", \"id-2\"])\n",
    "```\n",
    "\n",
    "__Delete all collections and items__\n",
    "* __Warning__: This will delete everything in the database!\n",
    "\n",
    "```python\n",
    "client.reset()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you've created and populated the `netflix_titles_test1` collection, it's time to query it!\n",
    "\n",
    "You'll use it to provide recommendations for films and TV shows about dogs to one of your colleagues who loves dogs!\n",
    "\n",
    "You've been also provided with two new Netflix titles stored in `new_data`. \n",
    "\n",
    "You'll either add or update these IDs in the database depending on whether they're already present in the collection.\n",
    "\n",
    "__Instructions__\n",
    "\n",
    "* Retrieve the netflix_titles collection, specifying the OpenAI embedding function so the query is embedded using the same function as the documents.\n",
    "* Extract the IDs and documents from `new_data`, and use a single method to update them in the `netflix_titles_test1` collection if they already exist and add them if they don't\n",
    "* After you've added/updated the items, delete the item with ID 's95'.\n",
    "* Query the collection for \"films about dogs\" and return three results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ids': [['s2057', 's830', 's500']], 'embeddings': None, 'documents': [[\"Title: Hotel for Dogs (Movie)\\nDescription: Placed in a foster home that doesn't allow pets, 16-year-old Andi and her younger brother Bruce turn an abandoned hotel into a home for their dog.\\nCategories: Children & Family Movies, Comedies\", 'Title: Dog Gone Trouble (Movie)\\nDescription: The privileged life of a pampered dog named Trouble is turned upside-down when he gets lost and must learn to survive on the big-city streets.\\nCategories: Children & Family Movies, Comedies', 'Title: Dogs (TV Show)\\nDescription: These six intimate stories explore the abiding emotional bonds that form between dogs and their caregivers, no matter the circumstances.\\nCategories: Docuseries']], 'uris': None, 'data': None, 'metadatas': [[None, None, None]], 'distances': [[0.8885394334793091, 0.8959437608718872, 0.9038522839546204]], 'included': [<IncludeEnum.distances: 'distances'>, <IncludeEnum.documents: 'documents'>, <IncludeEnum.metadatas: 'metadatas'>]}\n"
     ]
    }
   ],
   "source": [
    "new_data= [{\"id\": \"s1001\", \"document\": \"Title: Cats & Dogs (Movie)\\nDescription: A look at the top-secret, high-tech espionage war going on between cats and dogs, of which their human owners are blissfully unaware.\"},\n",
    " {\"id\": \"s6884\", \"document\": 'Title: Goosebumps 2: Haunted Halloween (Movie)\\nDescription: Three teens spend their Halloween trying to stop a magical book, which brings characters from the \"Goosebumps\" novels to life.\\nCategories: Children & Family Movies, Comedies'}]\n",
    "\n",
    "# Retrieve the netflix_titles collection\n",
    "collection = client.get_collection(\n",
    "  name=\"netflix_titles\",\n",
    "  embedding_function=OpenAIEmbeddingFunction(model_name=\"text-embedding-3-small\", api_key=api_key)\n",
    ")\n",
    "\n",
    "\n",
    "# Update or add the new documents\n",
    "collection.upsert(\n",
    "    ids=[doc['id'] for doc in new_data],\n",
    "    documents=[doc['document'] for doc in new_data]\n",
    ")\n",
    "\n",
    "# Delete the item with ID \"s95\"\n",
    "collection.delete(ids=['s95'])\n",
    "\n",
    "# Query the collection for \"films about dogs\"\n",
    "result = collection.query(\n",
    "  query_texts=['films about dogs'],\n",
    "  n_results=3\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Multiple queries and filtering**\n",
    "\n",
    "### **Movie recommendations based on multiple datapoints**\n",
    "\n",
    "In the previous chapter, we used embeddings to make recommendations based on multiple data points. Let's do the same with the Netflix dataset and Chroma. We'll recommend movies related to other titles that a user has seen. Let's assume a user has seen a horror film and a kid's TV show:\n",
    "\n",
    "- Terrifier (id: 's8170)\n",
    "- Strawbery Shortcake: Berry Bitty Adventures (id: 's8103)\n",
    "\n",
    "It's an odd combination, but hopefully it will help differentiate the recommendations.\n",
    "\n",
    " we'll use the embedded texts of the reference items as queries. First, we're using `collection.get` to retrieve both of our reference texts. Notice that we're only extracting and storing the documents from these items in `reference_texts`. Since `collection.query` supports multiple query texts, we can pass our `reference_texts` directly; we'll ask for three results.\n",
    "\n",
    " ```python\n",
    "reference_ids = ['s8170', 's8103']\n",
    "\n",
    "reference_texts = collection.get(ids=reference_ids)['documents']\n",
    "\n",
    "result = collection.query(\n",
    "    query_texts= reference_texts,\n",
    "    n_results=3\n",
    ")\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ids': [['s8103', 's2968', 's3085'], ['s8170', 's5333', 's1368']], 'embeddings': None, 'documents': [[\"Title: Strawberry Shortcake: Berry Bitty Adventures (TV Show)\\nDescription: Join Strawberry Shortcake and her berry best friends in the whimsical land of Berry Bitty City, where they learn about teamwork and decision-making.\\nCategories: Kids' TV\", \"Title: Shopkins (TV Show)\\nDescription: Tiny grocery store items come to life as the Shopkins, who have fun adventures with each other at Small Mart and the magical town called Shopville.\\nCategories: Kids' TV\", \"Title: Rainbow Ruby (TV Show)\\nDescription: Ruby makes magical journeys with her teddy bear Choco to Rainbow Village, where her toys come to life – and where there's always a problem to solve!\\nCategories: Kids' TV\"], ['Title: Terrifier (Movie)\\nDescription: On Halloween night, inside a dilapidated apartment building, Art the Clown stalks his victims, slicing and slaughtering in terrifying silence.\\nCategories: Horror Movies, Independent Movies, Thrillers', 'Title: Demonic (Movie)\\nDescription: When amateur ghost hunters visit an abandoned house, their investigation turns into a massacre, leaving questions for a detective and a psychologist.\\nCategories: Horror Movies, Independent Movies', 'Title: Hell Fest (Movie)\\nDescription: A serial killer picks off a group of friends, one by one, as they make their way through a hell-themed amusement park.\\nCategories: Horror Movies']], 'uris': None, 'data': None, 'metadatas': [[None, None, None], [None, None, None]], 'distances': [[8.947264404923772e-07, 0.790496289730072, 0.8518878221511841], [1.5096826246008277e-05, 0.749109148979187, 0.7873519062995911]], 'included': [<IncludeEnum.distances: 'distances'>, <IncludeEnum.documents: 'documents'>, <IncludeEnum.metadatas: 'metadatas'>]}\n"
     ]
    }
   ],
   "source": [
    "reference_ids = ['s8170', 's8103']\n",
    "\n",
    "reference_texts = collection.get(ids=reference_ids)['documents']\n",
    "\n",
    "result = collection.query(\n",
    "    query_texts= reference_texts,\n",
    "    n_results=3\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
