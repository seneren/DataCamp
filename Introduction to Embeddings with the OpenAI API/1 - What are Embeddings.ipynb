{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating an Embedding request\n",
    "\n",
    "OpenAI provides access to their embedding models via the Embeddings endpoint, and requests to it take a very similar form to other OpenAI endpoints. \n",
    "\n",
    "We'll use the openAI lybrary to create requests to the OpenAI API, which also requires us to have an OpenAI API key.\n",
    "\n",
    "```python\n",
    "    from openai import OpenAI\n",
    "\n",
    "    client = OpenAI(api_key=\"<OPENAI_API_KEY>\")\n",
    "\n",
    "    response = client.embeddings.create(\n",
    "        model = \"text-embedding-3-small\"\n",
    "        input = \"Embeddings are a numerical representation of text that can be used to measure the relatedness between two pieces of text.\"\n",
    ")\n",
    "```\n",
    "\n",
    "We have specified input here as a text string, but the argument also accepts a list of strings.\n",
    "\n",
    "Finally, we'll call the `.model_dump()` method on the response to convert it into a dictionary, which is easier to work with, and print the result.\n",
    "\n",
    "```python\n",
    "response_dict = response.model_dump()\n",
    "print(response_dict)\n",
    "```\n",
    "<img src='./images/embedding_response.png' width=60% height=60% >\n",
    "\n",
    "The response from the API is extremely long, as the embedding model outputs 1536 numbers to represent the input string. Because we converted the response into a dictionary, we can dig into it using list and dictionary subsetting.\n",
    "\n",
    "Here we can print the full list of 1536 numbers representing our text:\n",
    "\n",
    "```pyton\n",
    "print(response_dict[\"data\"][0][\"embedding\"])\n",
    "```\n",
    "\n",
    "Output: `[0.0023064255, ..., -0.0028842222]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigating the vector space\n",
    "\n",
    "### Example: Embedding headlines\n",
    "\n",
    "We'll be working wit a dataset of news articles stored in a list if dictionaries\n",
    "\n",
    "```python\n",
    "    articles = [\n",
    "        {\"headline\": \"Economic Growth Continues Amid Global Uncertainty\", \"topic\": \"Business\"},\n",
    "        {\"headline\": \"Interest rates fall to historic lows\", \"topic\": \"Business\"},\n",
    "        {\"headline\": \"Scientists Make Breakthrough Discovery in Renewable Energy\", \"topic\": \"Science\"},\n",
    "        {\"headline\": \"India Successfully Lands Near Moon's South Pole\", \"topic\": \"Science\"},\n",
    "        {\"headline\": \"New Particle Discovered at CERN\", \"topic\": \"Science\"},\n",
    "        {\"headline\": \"Tech Company Launches Innovative Product to Improve Online Accessibility\"},\n",
    "        {\"headline\": \"Tech Giant Buys 49% Stake In AI Startup\", \"topic\": \"Tech\"},\n",
    "        {\"headline\": \"New Social Media Platform Has Everyone Talking!\", \"topic\": \"Tech\"},\n",
    "        {\"headline\": \"The Blues get promoted on the final day of the season!\", \"topic\": \"Sport\"},\n",
    "        {\"headline\": \"1.5 Billion Tune-in to the World Cup Final\", \"topic\": \"Sport\"}\n",
    "]\n",
    "```\n",
    "\n",
    "**Embedding multiple inputs**\n",
    "\n",
    "We'll extract each article's headline using a list comprehension, accessing the headline key from each dictionary. \n",
    "\n",
    "```python\n",
    "    headline_text = [article[\"headline\"] for article in articles]       # list comprehension\n",
    "    headline_text\n",
    "```\n",
    "\n",
    "Output: `[\"Economic Growth Continues Amid Global Uncertainty\", \"topic\": \"Business\", ..., \"1.5 Billion Tune-in to the World Cup Final\", \"topic\": \"Sport\"]`\n",
    "\n",
    "To compute the embeddings, we can pass this entire list as an input to the create method. Batching the embeddings in this way is much more efficient than making API calls for each input.\n",
    "\n",
    "__Response__\n",
    "\n",
    "```python\n",
    "    response = client.embeddings.create(\n",
    "        model= 'text-embedding-3-small,'\n",
    "        input=headline_text\n",
    "    )\n",
    "\n",
    "    response_dict = response.model_dump()\n",
    "```\n",
    "\n",
    "The response output only differs from the single-input case in one way: where before, the list under the data key contained a single dictionary for the embeddings, in the multiple-input case, there is one dictionary for each input.\n",
    "\n",
    "<img src='./images/multi-embedding_response.png' width=60% height=60%>\n",
    "\n",
    "**Embedding multiple inputs**\n",
    "\n",
    "To extract these embeddings from the response and store them in the articles list of dictionaries, we loop over the indexes and articles using enumerate. For each article, we assign the embedding at the same index in the response to the article's embedding key.\n",
    "\n",
    "```python\n",
    "    for i, article in enumerate(articles):\n",
    "        article[\"embedding\"] = response_dict[\"data\"][i][\"embedding\"]\n",
    "```\n",
    "\n",
    "__Note that `article` itself is a dictionary under the `articles` dictionary, so we can assign the embedding to the `embedding` key in the same way we would assign any other value. the index `i` corresponds to the index of the article in the `articles` list and the index of the embedding in the `response_dict[\"data\"]` list. So we properly assign the embedding to the correct article.__\n",
    "\n",
    "Let's print the first two articles\n",
    "\n",
    "```python\n",
    "    print(articles[:2])\n",
    "```\n",
    "\n",
    "<img src= '/Users/erensen/Downloads/DataCamp/Introduction to Embeddings with the OpenAI API/images/milti-embedded-articles-dict_first-two.png' width=60% height=60%>\n",
    "\n",
    "We succesfully created embeddings for multiple inputs!\n",
    "\n",
    "Let's investigate these numbers more closely.\n",
    "\n",
    "**How long is the embeddings vector?**\n",
    "\n",
    "* \"Economic Growth Continues Amid Global Uncertainty\"\n",
    "```python\n",
    "    print(articles[0][\"embedding\"])\n",
    "```\n",
    "\n",
    "Output: `1536`\n",
    "\n",
    "For the first article in the list, the embedding model returns 1536numbers representing the semantic meaning of its headline, or in other words, its _position_, or _vector_, in the _vector space_.\n",
    "\n",
    "Another longer headline:\n",
    "\n",
    "* \"Tech Company Launches Innovative Product to Improve Accessibility\"\n",
    "\n",
    "```python\n",
    "    print(articles[5][\"embedding\"])\n",
    "```\n",
    "Output: `1536`\n",
    "\n",
    "We get the same number again!\n",
    "\n",
    "This is a key property of OpenAI's embedding models - they always return 1536 numbers, no matter the input.\n",
    "\n",
    "**Dimensionality reduction and t-SNE**\n",
    "\n",
    "Let's visualize our embeddings to better understand the model's results.\n",
    "\n",
    "We'll first need to reduce the number of dimensions from 1536 to something more manageable, like 2! There are lots of techniques for dimensionality _reduction_, but we'll use __t-SNE (t-distributed Stochastic Neighbor Embedding)__, which is a popular choice for visualizing high-dimensional data.\n",
    "\n",
    "We'll implement t-SNE using scikit-learn, a popular Python library for machine learning tasks.\n",
    "\n",
    "First we import `TSNE` from `sklearn.manifold`, and `numpy` as `np`\n",
    "\n",
    "```python\n",
    "    from sklearn.manifold import TSNE\n",
    "    import numpy as np\n",
    "```\n",
    "\n",
    "Next, we'll extract the embeddings from our articles list of dictionaries using list comprehension. to implement t-SNE, we create a TSNE instance and assing it to the tsne variable. We specify two arguments: \n",
    "* `n_components`: the number of dimensions we want to reduce to\n",
    "* `perplexity`: used by the algorithm in the transformation. The default value is normally fine, but for smaller datasets, it must be reduced to a numer less than the number of data points. Since we have 10 articles, we'll set it to 5.\n",
    "\n",
    "```python\n",
    "    embeddings = np.array([article[\"embedding\"] for article in articles])\n",
    "\n",
    "    tsne = TSNE(n_components=2, perplexity=5)\n",
    "```\n",
    "\n",
    "Finally, to perform the t-SNE transformation, we call the `fit_transform` method on the `tsne` object, passing it in the embeddings as a NumPy array. This will return the transformed embeddings in a NumPy array with `n_components` dimensions, which we can now visualize.\n",
    "\n",
    "```python\n",
    "    transformed_embeddings = tsne.fit_transform(np.array(embeddings))\n",
    "```\n",
    "\n",
    "Altough t-SNE is useful for exploring and visualizing igher dimensions, it will result in the loss of some information in the transformation, so it should be used with caution.\n",
    "\n",
    "To visualize these transformed embeddings, we call `plt.scatter` from `Matplotlib` on the first and the second columns of the `embeddings_2d` array. We'll also include some code to extract the article topics, annotate the plot with them, and display the plot.\n",
    "\n",
    "```python\n",
    "    plt.scatter(transformed_embeddings[:, 0], transformed_embeddings[:, 1])\n",
    "\n",
    "    topics = [article[\"topic\"] for article in articles]\n",
    "    for i, topic in enumerate(topics):\n",
    "        plt.annotate(topic, (transformed_embeddings[i, 0], transformed_embeddings[i, 1]))\n",
    "\n",
    "    plt.show()\n",
    "```\n",
    "\n",
    "the full code is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "articles = [\n",
    "        {\"headline\": \"Economic Growth Continues Amid Global Uncertainty\", \"topic\": \"Business\"},\n",
    "        {\"headline\": \"Interest rates fall to historic lows\", \"topic\": \"Business\"},\n",
    "        {\"headline\": \"Scientists Make Breakthrough Discovery in Renewable Energy\", \"topic\": \"Science\"},\n",
    "        {\"headline\": \"India Successfully Lands Near Moon's South Pole\", \"topic\": \"Science\"},\n",
    "        {\"headline\": \"New Particle Discovered at CERN\", \"topic\": \"Science\"},\n",
    "        {\"headline\": \"Tech Company Launches Innovative Product to Improve Online Accessibility\", \"topic\": \"Tech\"},\n",
    "        {\"headline\": \"Tech Giant Buys 49% Stake In AI Startup\", \"topic\": \"Tech\"},\n",
    "        {\"headline\": \"New Social Media Platform Has Everyone Talking!\", \"topic\": \"Tech\"},\n",
    "        {\"headline\": \"The Blues get promoted on the final day of the season!\", \"topic\": \"Sport\"},\n",
    "        {\"headline\": \"1.5 Billion Tune-in to the World Cup Final\", \"topic\": \"Sport\"}\n",
    "]\n",
    "\n",
    "# Extract headlines\n",
    "headline_text = [article[\"headline\"] for article in articles]       # list comprehension\n",
    "headline_text\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = OpenAI(api_key=\"<OPENAI_API_KEY>\")\n",
    "\n",
    "# Generate embeddings for all headlines\n",
    "response = client.embeddings.create(\n",
    "    model= 'text-embedding-3-small',\n",
    "    input=headline_text\n",
    ")\n",
    "\n",
    "# Convert response to dictionary and store embeddings in articles\n",
    "response_dict = response.model_dump()\n",
    "for i, article in enumerate(articles):\n",
    "        article[\"embedding\"] = response_dict[\"data\"][i][\"embedding\"]\n",
    "\n",
    "\n",
    "# Convert embeddings to numpy array for t-SNE\n",
    "embeddings = np.array([article[\"embedding\"] for article in articles])\n",
    "\n",
    "# Initialize t-SNE with 2 components and perplexity of 5\n",
    "tsne = TSNE(n_components=2, perplexity=5)\n",
    "\n",
    "# Transform high-dimensional embeddings to 2D\n",
    "transformed_embeddings = tsne.fit_transform(np.array(embeddings))\n",
    "\n",
    "# Create scatter plot of transformed embeddings\n",
    "plt.scatter(transformed_embeddings[:, 0], transformed_embeddings[:, 1])\n",
    "\n",
    "# Add topic labes to the point\n",
    "topics = [article['topic'] for article in articles]\n",
    "for i, topic in enumerate(topics):\n",
    "    plt.annotate(topic, (transformed_embeddings[i, 0], transformed_embeddings[i, 1]))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the plot.\n",
    "\n",
    "<img src= './images/scatter-of-transformed-embeddings.png' width=50% height=50%>\n",
    "\n",
    "Notice that headlines with the same topic were clustered more closely together. In other words, model captured the semantic meaning of the headlines and mapped them based on it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "You've been provided with a list of dictionaries called `products`, which contains product information for different products sold by an online retailer. It's your job to embed the `'short_description'` for each product to enable semantic search for the retailer's website.\n",
    "\n",
    "Here's a preview of the products list of dictionaries:\n",
    "\n",
    "```python\n",
    "products = [\n",
    "    {\n",
    "        \"title\": \"Smartphone X1\",\n",
    "        \"short_description\": \"The latest flagship smartphone with AI-powered features and 5G connectivity.\",\n",
    "        \"price\": 799.99,\n",
    "        \"category\": \"Electronics\",\n",
    "        \"features\": [\n",
    "            \"6.5-inch AMOLED display\",\n",
    "            \"Quad-camera system with 48MP main sensor\",\n",
    "            \"Face recognition and fingerprint sensor\",\n",
    "            \"Fast wireless charging\"\n",
    "        ]\n",
    "    },\n",
    "    ...\n",
    "]\n",
    "```\n",
    "\n",
    "An OpenAI client has already been created as assigned to `client`.\n",
    "\n",
    "__Instructions__\n",
    "\n",
    "* Create a list called `product_descriptions` containing the `'short_description'` for each product in `products` using a list comprehension.\n",
    "* Create embeddings for each product `'short_description'` using __batching__, passing the input to the `text-embedding-3-small` model.\n",
    "* Extract the embeddings for each product from `response_dict` and store them in `products` under a new key called `'embedding'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products = [\n",
    "    {\n",
    "        \"title\": \"Smartphone X1\",\n",
    "        \"short_description\": \"The latest flagship smartphone with AI-powered features and 5G connectivity.\",\n",
    "        \"price\": 799.99,\n",
    "        \"category\": \"Electronics\",\n",
    "        \"features\": [\n",
    "            \"6.5-inch AMOLED display\",\n",
    "            \"Quad-camera system with 48MP main sensor\",\n",
    "            \"Face recognition and fingerprint sensor\",\n",
    "            \"Fast wireless charging\"\n",
    "        ]\n",
    "    },\n",
    "    ...\n",
    "]\n",
    "\n",
    "# Extract a list of product short descriptions from products\n",
    "product_descriptions = [product['short_description'] for product in products]\n",
    "\n",
    "# Create embeddings for each product description\n",
    "response = client.embeddings.create(\n",
    "  model=\"text-embedding-3-small\",\n",
    "  input=product_descriptions\n",
    ")\n",
    "response_dict = response.model_dump()\n",
    "\n",
    "# Extract the embeddings from response_dict and store in products\n",
    "for i, product in enumerate(products):\n",
    "    product['embedding'] = response_dict['data'][i]['embedding']\n",
    "    \n",
    "print(products[0].items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create two lists by extracting information from `products` using list comprehensions: `categories`, containing the `'category'` of each product, and `embeddings`, containing the embedded short description.\n",
    "* Reduce the number of embeddings dimensions from 1,536 to two using the `tsne` model provided.\n",
    "* Create a scatter plot of the 2D embeddings, plotting the first column from `embeddings_2d` on the x-axis and the second column on the y-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create categories and embeddings lists using list comprehensions\n",
    "categories = [product['category'] for product in products]\n",
    "embeddings = [product['embedding'] for product in products]\n",
    "\n",
    "# Reduce the number of embeddings dimensions to two using t-SNE\n",
    "tsne = TSNE(n_components=2, perplexity=5)\n",
    "embeddings_2d = tsne.fit_transform(np.array(embeddings))\n",
    "\n",
    "# Create a scatter plot from embeddings_2d\n",
    "plt.scatter(embeddings_2d[:,0], embeddings_2d[:,1])\n",
    "\n",
    "for i, category in enumerate(categories):\n",
    "    plt.annotate(category, (embeddings_2d[i, 0], embeddings_2d[i, 1]))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output: \n",
    "\n",
    "<img src= ./images/plot-of-exercise.png width=50% height=50%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Similarity\n",
    "\n",
    "Recall that embedding models map semantically similar texts more closely together in the vector space. This means that we can measure how semantically similar two pieces of text are by computing the distance between the vectors in the vector space.\n",
    "\n",
    "### Measuring similarity\n",
    "\n",
    "**Cosine distance**\n",
    "\n",
    "The cosine distance uses linear algebra, to evaluate the similarity between two vectors.\n",
    "\n",
    "To compute the cosine distance between two vectors, we can use the `cosine` function from the `scipy.spatial.distance` module. First we import `distance` from `scipy.spatial` and then we compute the cosine distance between the vectors.\n",
    "\n",
    "```python\n",
    "    from scipy.spatial import distance\n",
    "\n",
    "    distance.cosine(vector1, vector2)\n",
    "```\n",
    "\n",
    "Here, vector1 and vector2 are the vectors of n-tuple. In 2D, the vectors are of the form (x, y). So, vector1 can be (0,1) and vector2 can be (1,0). When passing it to the cosine function, we write them with __square brackets__, instead of parantheses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "2.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial import distance\n",
    "\n",
    "print(distance.cosine([0,1], [1,0]))\n",
    "print(distance.cosine([0,1], [0,-1]))\n",
    "print(distance.cosine([0,1], [0,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the distance range from 0 to 2, where small number indicate high similarity.\n",
    "\n",
    "let's try this on text embeddings:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create embeddings in a more repeatable way, we'll define a custom function to send a request to the API, and extract and return embeddings from the response.\n",
    "\n",
    "```python\n",
    "    def create_embeddings(text):\n",
    "        response = client.embeddings/create(\n",
    "            model=\"text-embedding-3-small\",\n",
    "            input=text\n",
    "        )\n",
    "    response_dict = response.model_dump(\n",
    "\n",
    "    return [data['embedding'] for data in response_dict['data']]\n",
    "    )\n",
    "```\n",
    "\n",
    "This function can be called on a single string, or a list of strings, and always retuns a list of lists.\n",
    "\n",
    "To just return a single list of embeddings for the single string case, make sure to 0-index the function's result.\n",
    "\n",
    "```python\n",
    "print(create_embeddings([\"Python is the best!\", \"R is the best\"]))\n",
    "print(create_embeddings(\"Datacamp is awesome!\")[0])\n",
    "```\n",
    "\n",
    "First, we'll import `distance` from `scipy.spacial` for the cosine distance calculations, and NumPy to access its `argmin` function, which returns the index of the minimum value in an array.\n",
    "\n",
    "```python\n",
    "    from scipy.spatial import distance\n",
    "    import numpy as np\n",
    "```\n",
    "\n",
    "Let's start with a piece of text to compare to our embedded headlines: computer.<br>\n",
    "We'll stary by embedding this text using our `create_embeddings` custom function, remembering to 0-index the result.\n",
    "\n",
    "```python\n",
    "    search_text = \"computer\"\n",
    "    search_embedding = create_embeddings(search_text)[0]\n",
    "```\n",
    "\n",
    "To find the most similar headline to this text, we'll loop over each article, calculating the cosine distance between each embedded headline and the embedded query. We start by creating an empty list to store the distances, and loop over each article in our articles list of dictionaries. Next we calculate the cosine distance between the text and headline by calling `distance.cosine`, passing it the embedded text and headline. Finally we append this distanve to the distances list.\n",
    "\n",
    "```python\n",
    "    distances = []\n",
    "    for article in articles:\n",
    "        headline_embedding = article[\"headline_embedding\"]\n",
    "        dist = distance.cosine(search_embedding, article['embedding'])\n",
    "        distances.append(dist)\n",
    "```\n",
    "\n",
    "The most similar headline will have the smallest cosine distance, so we can use NumPy's `argmin` function to return the index of the smallest value in the distances list; then, use it to subset the article at this index and return its headline.\n",
    "\n",
    "```python\n",
    "    min_dist_ind = np.argmin(distances)\n",
    "    print(f\"Most similar headline: {articles[min_dist_ind]['headline']}\")\n",
    "```\n",
    "\n",
    "\n",
    "The full code is as follows:\n",
    "```python\n",
    "    from scipy.spatial import distance\n",
    "    import numpy as np\n",
    "\n",
    "    \"\"\"articles list is given above.\"\"\"\n",
    "\n",
    "    def create_embeddings(text):\n",
    "        response = client.embeddings.create(\n",
    "            model=\"text-embedding-3-small\",\n",
    "            input=text\n",
    "        )\n",
    "    response_dict = response.model_dump(\n",
    "\n",
    "    return [data['embedding'] for data in response_dict['data']]\n",
    "    )\n",
    "\n",
    "    search_text = \"computer\"\n",
    "    search_embedding = create_embeddings(search_text)[0]\n",
    "\n",
    "    distances = []\n",
    "    for article in articles:\n",
    "        headline_embedding = article[\"headline_embedding\"]\n",
    "        dist = distance.cosine(search_embedding, article['embedding'])\n",
    "        distances.append(dist)\n",
    "\n",
    "    min_dist_ind = np.argmin(distances)\n",
    "    print(f\"Most similar headline: {articles[min_dist_ind]['headline']}\")\n",
    "```\n",
    "\n",
    "Output: <br>\n",
    "`Most similar headline: Tech Company Launches Innovative Product to Improve Online Accessibility`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
