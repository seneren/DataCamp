{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Sequential chains**\n",
    "\n",
    "Some problems can only be solved sequentially. \n",
    "\n",
    "Consider a chatbot used to create a travel itinerary\n",
    "\n",
    "We need to tell the chatbot our destination, receive suggestions on what to see on our trip, and tell the model which activities to select to compile the itinerary.\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src='./images/sequential-problem.png' width=50%>\n",
    "</div>\n",
    "\n",
    "This is a sequential problem, as it requires more than one user input:\n",
    "- One to specify the destination\n",
    "- One to select the activities\n",
    "\n",
    "In sequential chains, the output from one chain becomes the input to another.\n",
    "\n",
    "We'll create two prompt templates: one to generate suggestions for activities from the input destination, and another to create an itinerary for one day of activities from the model's top three suggestions. \n",
    "\n",
    "```python\n",
    "destination_prompt = PromptTemplate(\n",
    "    input_variables = [\"destination\"],\n",
    "    template = \"I am planning a trip to {destination}. Can you suggest some activities to do there?\"\n",
    ")\n",
    "activities_prompt = PromptTemplate(\n",
    "    input_variables = [\"activities\"],\n",
    "    template = \"I only have one day, so can you create an itinerary from your top three activities: {activities}\"\n",
    ")\n",
    "```\n",
    "\n",
    "We define our model, and begin our sequential chain. \n",
    "\n",
    "```python\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    api_key=\"<OPENAI_API_KEY>\"\n",
    ")\n",
    "```\n",
    "\n",
    "We start by defining a dictionary that passes our destination prompt template to the LLM and parses the output to a string, all using LCEL's pipe. This gets assigned to the \"activities\" key, which is important, as this is the input variable to the second prompt template. We pipe the first chain into the second prompt template, then into the LLM, and again, parse to a string. We also wrap the sequential chain in parentheses so we can split this code across multiple lines. \n",
    "\n",
    "```python\n",
    "seq_chain = (\n",
    "    {\"activities\": destination_prompt | llm | StrOutputParser()}\n",
    "    | activities_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "```\n",
    "\n",
    "To summarize: the `destination_prompt` is passed to the `LLM` to generate the activity suggestions, and the output is parsed to a string and assigned to `\"activities\"`. This is passed to the second `activities_prompt`, which is passed to the `LLM` to generate the itinerary, which is parsed as a string.\n",
    "\n",
    "`\"activities\"` (`destination_prompt` → `llm` (this generates activity suggestions) → parse the suggestions output to string by using `StrOutputParser()`) →  pass `activities` to `activities_prompt` → pass `activities_prompt` to `llm` (this generates the itinerary) → parse itinerary output to string by using `StrOutputParser()`.\n",
    "\n",
    "Let's invoke the hain, passing \"Rome\" as our input destination.\n",
    "\n",
    "```python\n",
    "print(seq_chain.invoke({\"destination\": \"Rome\"}))\n",
    "```\n",
    "\n",
    "<img src='./images/sequential-travel.png' width=70%>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly! Here’s a one-day itinerary focusing on three top activities to make the most of your time in Rome:\n",
      "\n",
      "### Morning\n",
      "\n",
      "**1. Visit the Colosseum** (around 9:00 AM)  \n",
      "- Start your day early at the Colosseum, one of the city’s most iconic landmarks. Book a timed entry ticket in advance to skip the lines and spend some time exploring the grandeur of this ancient amphitheater. Don’t miss the underground section and the upper tiers for incredible views.\n",
      "\n",
      "**2. Explore the Roman Forum** (around 11:00 AM)  \n",
      "- Just a short walk from the Colosseum, the Roman Forum is a captivating site filled with ruins that tell the story of Ancient Rome. Spend about an hour here, taking in the historical significance and imagining what life was like during the empire's height.\n",
      "\n",
      "### Lunch\n",
      "\n",
      "**Lunch in Trastevere** (around 12:30 PM)  \n",
      "- Head to the charming neighborhood of Trastevere for lunch. Choose a local trattoria to enjoy authentic Roman cuisine—try dishes like cacio e pepe or pasta alla carbonara. Don’t forget to top it off with some delicious gelato!\n",
      "\n",
      "### Afternoon\n",
      "\n",
      "**3. Vatican Museums and St. Peter's Basilica** (around 2:30 PM)  \n",
      "- After lunch, make your way to the Vatican Museums (reserve tickets in advance). Spend some time exploring the vast collection of art, with highlights including the Raphael Rooms and the Sistine Chapel. After the museums, visit St. Peter’s Basilica, where you can marvel at Michelangelo’s Pietà and climb to the dome for breathtaking views of the city.\n",
      "\n",
      "### Evening\n",
      "\n",
      "**Relax at Piazza Navona** (around 5:30 PM)  \n",
      "- Head over to Piazza Navona, one of Rome's most beautiful squares. Enjoy the stunning Baroque fountains and street performers, and perhaps indulge in some more gelato as you soak in the atmosphere.\n",
      "\n",
      "### Optional Night Activity\n",
      "\n",
      "**Dinner and Stroll** (around 7:00 PM)  \n",
      "- After a day of sightseeing, find a cozy restaurant in the area for dinner. If you have energy left, take a leisurely evening stroll through the streets of Rome, or perhaps along the Tiber River, to see some of the city’s landmarks beautifully lit up at night.\n",
      "\n",
      "This itinerary allows you to experience a blend of Rome's historical, cultural, and culinary delights in just one day. Enjoy your visit!\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser   # to parse the output to string\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "destination_prompt = PromptTemplate(\n",
    "    input_variables = [\"destination\"],\n",
    "    template = \"I am planning a trip to {destination}. Can you suggest some activities to do there?\"\n",
    ")\n",
    "activities_prompt = PromptTemplate(\n",
    "    input_variables = [\"activities\"],\n",
    "    template = \"I only have one day, so can you create an itinerary from your top three activities: {activities}\"\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    api_key=api_key\n",
    ")\n",
    "\n",
    "seq_chain = (\n",
    "    {\"activities\": destination_prompt | llm | StrOutputParser()}\n",
    "    | activities_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(seq_chain.invoke({\"destination\": \"Rome\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text='I want to learn how to play golf. Can you suggest how I can learn this step-by-step?'\n"
     ]
    }
   ],
   "source": [
    "# Create a prompt template that takes an input activity\n",
    "learning_prompt = PromptTemplate(\n",
    "    input_variables=[\"activity\"],\n",
    "    template=\"I want to learn how to {activity}. Can you suggest how I can learn this step-by-step?\"\n",
    ")\n",
    "\n",
    "# Create a prompt template that places a time constraint on the output\n",
    "time_prompt = PromptTemplate(\n",
    "    input_variables= [\"learning_plan\"],\n",
    "    template=\"I only have one week. Can you create a plan to help me hit this goal: {learning_plan}.\"\n",
    ")\n",
    "\n",
    "# Invoke the learning_prompt with an activity\n",
    "print(learning_prompt.invoke({\"activity\": \"play golf\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly! Since you have a week to kickstart your classical guitar journey, here's a focused 7-day plan that incorporates the steps you've outlined while ensuring you stay engaged and make solid progress.\n",
      "\n",
      "### 7-Day Classical Guitar Learning Plan\n",
      "\n",
      "#### **Day 1: Set-Up and Familiarization**\n",
      "- **Equipment Setup**: Get your classical guitar, tuner, metronome, and footstool ready.\n",
      "- **Learn the Parts of the Guitar**: Spend 15-30 minutes understanding the anatomy of the guitar.\n",
      "- **Posture Practice**: Sit with the guitar and practice holding it correctly for 10-15 minutes.\n",
      "- **Tuning**: Use a tuner to learn how to tune your guitar properly.\n",
      "  \n",
      "#### **Day 2: Music Theory Basics**\n",
      "- **Notes and Frets**: Spend 30 minutes learning the names of the strings (E, A, D, G, B, E) and the first 5 frets.\n",
      "- **Reading Music**: Dedicate 30 minutes to understanding basic music notation and tablature through online resources or beginner books.\n",
      "- **Finger Placement**: Work on placing your left-hand fingers correctly over the frets.\n",
      "\n",
      "#### **Day 3: Introduction to Technique**\n",
      "- **Finger Exercises**: Start with finger warm-up exercises for 15 minutes to improve dexterity.\n",
      "- **Right-Hand Technique**: Spend 30 minutes learning and practicing rest strokes and free strokes with your right hand.\n",
      "- **Basic Scales**: Practice major scales (C and G) for 10-15 minutes, focusing on finger placement and timing.\n",
      "\n",
      "#### **Day 4: Start Learning Simple Pieces**\n",
      "- **Beginner Repertoire**: Choose a simple piece to start with (e.g., \"Romanza\"). Spend 30 minutes learning it.\n",
      "- **Practice Scales**: Continue practicing scales (increase to other major scales) for another 15-20 minutes.\n",
      "- **Chords**: Dedicate 15-20 minutes to learning basic chords like C, G, Am, and D. Practice transitioning between these chords.\n",
      "\n",
      "#### **Day 5: Review and Extend Your Skills**\n",
      "- **Review Techniques**: Spend 20 minutes going over finger placements and right-hand techniques.\n",
      "- **Learn Another Piece**: Pick another accessible piece (e.g., \"Malagueña\") and spend 30 minutes with it.\n",
      "- **Chord Progressions**: Spend 20 minutes practicing the chord progressions you learned.\n",
      "\n",
      "#### **Day 6: Incorporate Advanced Techniques**\n",
      "- **Arpeggios**: Spend 20 minutes learning and practicing arpeggio patterns.\n",
      "- **Dynamics and Expression**: Dedicate 20 minutes to exploring dynamics (playing softly/loudly) in the pieces you’ve learned.\n",
      "- **Practice**: Spend 20 minutes revisiting the pieces and focusing on dynamics.\n",
      "\n",
      "#### **Day 7: Reflection and Performance**\n",
      "- **Revisit Pieces**: Spend 30 minutes playing the pieces you’ve learned. Focus on applying techniques and dynamics.\n",
      "- **Record Yourself**: Consider recording a simple performance of one of the pieces to track your progress.\n",
      "- **Explore Online Resources**: Spend some time watching performances by classical guitarists online to inspire and enrich your understanding.\n",
      "- **Plan Next Steps**: Set goals for the coming weeks based on your interests and skills.\n",
      "\n",
      "### Daily Practice Tips:\n",
      "- **Set a Timer**: Keep your practice sessions focused and intentional by setting a timer for each segment.\n",
      "- **Stay Consistent**: Try to maintain consistency with your practice times and take breaks if needed to avoid fatigue.\n",
      "- **Have Fun**: Enjoy the process! If something doesn’t feel right, slow down, and focus on learning it at your own pace.\n",
      "\n",
      "This plan should give you a solid foundation in classical guitar over the course of a week while keeping you motivated and engaged. Good luck, and enjoy your musical journey!\n"
     ]
    }
   ],
   "source": [
    "learning_prompt = PromptTemplate(\n",
    "    input_variables=[\"activity\"],\n",
    "    template=\"I want to learn how to {activity}. Can you suggest how I can learn this step-by-step?\"\n",
    ")\n",
    "\n",
    "time_prompt = PromptTemplate(\n",
    "    input_variables=[\"learning_plan\"],\n",
    "    template=\"I only have one week. Can you create a plan to help me hit this goal: {learning_plan}.\"\n",
    ")\n",
    "\n",
    "# Complete the sequential chain with LCEL\n",
    "seq_chain = ({\"learning_plan\": learning_prompt | llm | StrOutputParser()}\n",
    "    | time_prompt\n",
    "    | llm\n",
    "    | StrOutputParser())\n",
    "\n",
    "# Call the chain\n",
    "print(seq_chain.invoke({\"activity\": \"play classic guitar\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Introduction to LangChain agents**\n",
    "\n",
    "### **What are agents?**\n",
    "\n",
    "\n",
    "  <div style=\"display: flex; align-items: flex-start;\">\n",
    "    <!-- Left Column -->\n",
    "    <div style=\"width: 30%; padding: 10px;\">\n",
    "    In LangChain, agents use language models to determine actions. <br><br>\n",
    "    Agents often use _tools_, which are functions called by the agent to interact with the system. These tools can be high-level utilities to transform inputs, or they can be task-specific. <br><br>\n",
    "    Agents can even use chains and other agents as tools! In this course, we'll discuss a type of agent called _ReAct agents_.\n",
    "    </div>\n",
    "    <!-- Right Column -->\n",
    "    <div style=\"width: 33%; padding: 10px;\">\n",
    "    <div>\n",
    "    <img src='./images/agent.png' width=90%>\n",
    "    </div>\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "### **ReAct agents**\n",
    "\n",
    "__ReAct__ stands for **Reason** and **Act**. And this is exactly how the agent operates.\n",
    "\n",
    "It prompts the model using a repeated loop of thinking, acting, and observing. If we were to ask a ReAct agent that had access to a weather tool, \"What is the weather like in Kingston, Jamaica?\", it would start by thinking about the task and which tool to call, call that tool using the information, and observe the results from the tool call.\n",
    "\n",
    "<img src='./images/react-loop.png' width=35%>\n",
    "\n",
    "To implement agents, we'll be using __LangGraph__, which is branch of the LangChain ecosystem specifically _for designing agentic systems_, or _systems including agents_. \n",
    "\n",
    "Like LangChain's core library, it's is built to provide a unified, tool-agnostic syntax. We'll be using the version 0.066 of LangGraph in this course.\n",
    "\n",
    "### **ReAct agent**\n",
    "\n",
    "We'll create a ReAct agent that can solve math problems - something most LLMs struggle with. \n",
    "\n",
    "1. We import `create_react_agent` from `langgraph` and the `load_tools()` function. \n",
    "2. We initialize our LLM, and load the `llm-math` tool using the `load_tools()` function. \n",
    "3. To create the agent, we pass the LLM and tools to `create_react_agent()`.\n",
    "4. Just like chains, agents can be executed with the `.invoke()` method. \n",
    "5. We pass the chat model a message to find the square root of `101`, which isn't a whole number.\n",
    "\n",
    "Let's see how the agent approaches the problem!\n",
    "\n",
    "```python\n",
    "from langgraph.prebuilt import create_react_agent                                         # 1.\n",
    "from langchain_community.agent_toolkits.load_tools import load_tools                      # 1.\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", api_key=\"<OPENAI_API_KEY>\")                         # 2.    \n",
    "tools = load_tools([\"llm-math\"], llm=llm)                                                 # 2.\n",
    "agent = create_react_agent(llm, tools)                                                    # 3.\n",
    "\n",
    "messages = agent.invoke({\"messages\":[(\"human\", \"What is the square root of 101?\")]})      # 4.\n",
    "print(messages)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='What is the square root of 101?', additional_kwargs={}, response_metadata={}, id='fec1a470-f5a9-462a-82d4-0e7a5fdca362'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_3mzOcQ0AByTlZTKl6AEtP9po', 'function': {'arguments': '{\"__arg1\":\"sqrt(101)\"}', 'name': 'Calculator'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 63, 'total_tokens': 83, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_709714d124', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-a78bfd2d-29bf-4e88-b8f0-64814bd9ea9d-0', tool_calls=[{'name': 'Calculator', 'args': {'__arg1': 'sqrt(101)'}, 'id': 'call_3mzOcQ0AByTlZTKl6AEtP9po', 'type': 'tool_call'}], usage_metadata={'input_tokens': 63, 'output_tokens': 20, 'total_tokens': 83, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='Answer: 10.04987562112089', name='Calculator', id='6bc3e1d5-2a32-4deb-a7bd-b1bdf3ad6788', tool_call_id='call_3mzOcQ0AByTlZTKl6AEtP9po'), AIMessage(content='The square root of 101 is approximately 10.05.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 99, 'total_tokens': 114, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_709714d124', 'finish_reason': 'stop', 'logprobs': None}, id='run-a776efdd-9a5f-4cc1-8b78-0656e2ee197f-0', usage_metadata={'input_tokens': 99, 'output_tokens': 15, 'total_tokens': 114, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n"
     ]
    }
   ],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_community.agent_toolkits.load_tools import load_tools\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", api_key=api_key) \n",
    "tools = load_tools([\"llm-math\"], llm=llm)\n",
    "agent = create_react_agent(llm, tools)\n",
    "\n",
    "messages = agent.invoke({\"messages\":[(\"human\", \"What is the square root of 101?\")]})\n",
    "print(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a lot of metadata in the output:\n",
    "```python\n",
    "{'messages': [\n",
    "HumanMessage(content='What is the square root of 101?', ...)\n",
    "\n",
    "AIMessage(content='', additional_kwargs={'tool_calls': [{'function': {'arguments': '{\"__arg1\":\"sqrt(101)\"}', 'name': 'Calculator'}}]}, ...)\n",
    "\n",
    "ToolMessage(content='Answer: 10.04987562112089', name='Calculator', ...)\n",
    "\n",
    "AIMessage(content='The square root of 101 is approximately 10.05.', ...)\n",
    "]}\n",
    "```\n",
    "\n",
    "The first is our prompt defining the problem.\n",
    "\n",
    "The second is created by the model to identify the tool to use and to convert our query into mathematical format.\n",
    "\n",
    "The third is the result of the tool call.\n",
    "\n",
    "The final message is the model's response after ovserving the tool's answer, which it decided to roun to two decimal places.\n",
    "\n",
    "If we just want the final response, we can subset the final message and extract it's content with the `.content` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The square root of 101 is approximately 10.05.\n"
     ]
    }
   ],
   "source": [
    "print(messages['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As of 2023, the estimated population of New York City is 8,258,035.\n"
     ]
    }
   ],
   "source": [
    "import wikipedia\n",
    "\n",
    "# Define the tools\n",
    "tools = load_tools([\"wikipedia\"])\n",
    "\n",
    "# Define the agent\n",
    "agent = create_react_agent(llm, tools)\n",
    "\n",
    "# Invoke the agent\n",
    "response = agent.invoke({\"messages\": [(\"human\", \"How many people live in New York City?\")]})\n",
    "print(response['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Custom tools for agents**\n",
    "\n",
    "Tools in LangChain must be formatted in a specific way to be compatible with agents. They must have a name, accessible via the `.name` attribute. A description, which is used by the LLM to determine when to call the tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name of the tool: wikipedia\n",
      "\n",
      "Description of the tool wikipedia: A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\n"
     ]
    }
   ],
   "source": [
    "print(\"Name of the tool: \" + tools[0].name + \"\\n\")\n",
    "print(\"Description of the tool \" + tools[0].name + \": \" + tools[0].description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the return_direct parameter indicates whether the agent should stop after invoking this tool, which it won't in this case. Understanding this required format will help us to understand how to create our own tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(tools[0].return_direct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Defining a custom function**\n",
    "\n",
    "Let's say we want to define a Python function to generate a financial report for a company. It takes three arguments: \n",
    "- The `company_name`,\n",
    "- `revenue`,\n",
    "- and `expenses`.\n",
    "\n",
    "And outputs - a string containing the `net_income`. We make the use of this function clear in the _docstring_, defined using triple quotes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def financial_report(company_name: str, revenue: int, expenses: int) -> str:\n",
    "    \"\"\"Generate a financial report for a company that calculates net income\"\"\"\n",
    "    net_income = revenue - expenses\n",
    "\n",
    "    report = f\"Financial Report for {company_name}:\\n\"\n",
    "    report += f\"Revenue: ${revenue}\\n\"\n",
    "    report += f\"Expenses: ${expenses}\\n\"\n",
    "    report += f\"Net Income: ${net_income}\\n\"\n",
    "    return report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's what the report looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Financial Report for LemonadeStand:\n",
      "Revenue: $100\n",
      "Expenses: $50\n",
      "Net Income: $50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(financial_report(company_name=\"LemonadeStand\", revenue=100, expenses=50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's convert this function into a tool our agent can call.\n",
    "\n",
    "### **From functions to tools**\n",
    "\n",
    "To do this, we import the `@tool` __decorator__ and add it before the function definition. The @tool modifies the function so it's in the correct format to be used by a tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool               # <--- This is the new line\n",
    "def financial_report(company_name: str, revenue: int, expenses: int) -> str:\n",
    "    \"\"\"Generate a financial report for a company that calculates net income\"\"\"\n",
    "    net_income = revenue - expenses\n",
    "\n",
    "    report = f\"Financial Report for {company_name}:\\n\"\n",
    "    report += f\"Revenue: ${revenue}\\n\"\n",
    "    report += f\"Expenses: ${expenses}\\n\"\n",
    "    report += f\"Net Income: ${net_income}\\n\"\n",
    "    return report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Examining the new tool**\n",
    "\n",
    "Like with the built-in tool we were looking at, we can now examine the various attributes of our tool. These include its name, which is the function name by default, its description, which is the function's docstring, and `return_direct`, which is set to False by default. We can also print the tools arguments, which lay out the argument names and expected data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "financial_report\n",
      "Generate a financial report for a company that calculates net income\n",
      "False\n",
      "{'company_name': {'title': 'Company Name', 'type': 'string'}, 'revenue': {'title': 'Revenue', 'type': 'integer'}, 'expenses': {'title': 'Expenses', 'type': 'integer'}}\n"
     ]
    }
   ],
   "source": [
    "print(financial_report.name)\n",
    "print(financial_report.description)\n",
    "print(financial_report.return_direct)\n",
    "print(financial_report.args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Integrating the custom tool**\n",
    "\n",
    "We'll again use a ReAct agent, combining the chat LLM with a list of tools to use, containing our new custom tool. We invoke the agent with an input containing the required information: a _company name_, _revenue_, and _expenses_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='TechStack generated made $10 million with $5 million of costs. Generate a financial report.', additional_kwargs={}, response_metadata={}, id='03aff138-cc90-4329-bf0b-d741d11013c0'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_JB0rEfU9Qj2G43ZpLAMS34SE', 'function': {'arguments': '{\"company_name\":\"TechStack\",\"revenue\":10000000,\"expenses\":5000000}', 'name': 'financial_report'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 31, 'prompt_tokens': 77, 'total_tokens': 108, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_709714d124', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-6f406c05-0991-450f-bc0d-de234ed3feba-0', tool_calls=[{'name': 'financial_report', 'args': {'company_name': 'TechStack', 'revenue': 10000000, 'expenses': 5000000}, 'id': 'call_JB0rEfU9Qj2G43ZpLAMS34SE', 'type': 'tool_call'}], usage_metadata={'input_tokens': 77, 'output_tokens': 31, 'total_tokens': 108, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='Financial Report for TechStack:\\nRevenue: $10000000\\nExpenses: $5000000\\nNet Income: $5000000\\n', name='financial_report', id='81df2e12-defc-44fb-a5f6-02e355996d16', tool_call_id='call_JB0rEfU9Qj2G43ZpLAMS34SE'), AIMessage(content=\"Here's the financial report for TechStack:\\n\\n- **Revenue:** $10,000,000\\n- **Expenses:** $5,000,000\\n- **Net Income:** $5,000,000 \\n\\nThe company has achieved a net income of $5 million.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 56, 'prompt_tokens': 143, 'total_tokens': 199, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_709714d124', 'finish_reason': 'stop', 'logprobs': None}, id='run-9d185db7-cb67-4653-a36c-8aa9bb3ace1b-0', usage_metadata={'input_tokens': 143, 'output_tokens': 56, 'total_tokens': 199, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n"
     ]
    }
   ],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model = \"gpt-4o-mini\",\n",
    "    api_key =api_key\n",
    ")\n",
    "agent = create_react_agent(llm, [financial_report])\n",
    "\n",
    "messages = agent.invoke({\"messages\": [(\"human\", \"TechStack generated made $10 million with $5 million of costs. Generate a financial report.\")]})\n",
    "print(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The response from the agent starts with our input, then determines that the financial_report tool should be called, which returns a tool message containing the output from our function, and finally, the output is passed to the LLM, which responds to us. Let's zoom in on this final message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's the financial report for TechStack:\n",
      "\n",
      "- **Revenue:** $10,000,000\n",
      "- **Expenses:** $5,000,000\n",
      "- **Net Income:** $5,000,000 \n",
      "\n",
      "The company has achieved a net income of $5 million.\n"
     ]
    }
   ],
   "source": [
    "print(messages['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Financial Report for TechStack:\n",
      "Revenue: $10000000\n",
      "Expenses: $5000000\n",
      "Net Income: $5000000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Recal the financial_report tool directly\n",
    "print(financial_report(company_name=\"TechStack\", revenue=10000000, expenses=5000000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that ther's slight formatting differences between the two: the LLM received the tool output, and put it's own slight spin on it, which we may need to watch out for."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    id                  name subscription_type  active_users  auto_renewal\n",
      "3  104  Peak Performance Co.           Premium           800          True\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"./datasets/customers.csv\")\n",
    "\n",
    "customers = pd.DataFrame(df)\n",
    "\n",
    "# Define a function to retrieve customer info by-name\n",
    "def retrieve_customer_info(name: str) -> str:\n",
    "    \"\"\"Retrieve customer information based on their name.\"\"\"\n",
    "    # Filter customers for the customer's name\n",
    "    customer_info = customers[customers['name'] == name]\n",
    "    return customer_info.to_string()\n",
    "  \n",
    "# Call the function on Peak Performance Co.\n",
    "print(retrieve_customer_info(\"Peak Performance Co.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': {'title': 'Name', 'type': 'string'}}\n"
     ]
    }
   ],
   "source": [
    "# Convert the retrieve_customer_info function into a tool\n",
    "@tool\n",
    "def retrieve_customer_info(name: str) -> str:\n",
    "    \"\"\"Retrieve customer information based on their name.\"\"\"\n",
    "    customer_info = customers[customers['name'] == name]\n",
    "    return customer_info.to_string()\n",
    "  \n",
    "# Print the tool's arguments\n",
    "print(retrieve_customer_info.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Summary of Customer: Peak Performance Co.**\n",
      "\n",
      "- **ID:** 104\n",
      "- **Subscription Type:** Premium\n",
      "- **Active Users:** 800\n",
      "- **Auto-Renewal:** Enabled\n",
      "\n",
      "**Statistics Overview:**\n",
      "Peak Performance Co. holds a Premium subscription with an active user base of 800. The account is set to auto-renew, ensuring uninterrupted service for their team.\n"
     ]
    }
   ],
   "source": [
    "# Create a ReAct agent\n",
    "agent = create_react_agent(llm, [retrieve_customer_info])\n",
    "\n",
    "# llm has already beed defined in the few cells above\n",
    "llm = ChatOpenAI(\n",
    "    model = \"gpt-4o-mini\",\n",
    "    api_key =api_key\n",
    ")\n",
    "\n",
    "# Invoke the agent on the input\n",
    "messages = agent.invoke({\"messages\": [(\"human\", \"Create a summary and a few sentences of the stats of our customer: Peak Performance Co.\")]})\n",
    "print(messages['messages'][-1].content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
