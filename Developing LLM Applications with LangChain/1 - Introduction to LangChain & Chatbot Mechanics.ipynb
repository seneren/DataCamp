{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **The LangChain Ecosystem**\n",
    "\n",
    "### **What is LangChain?**\n",
    "\n",
    "  <div style=\"display: flex;\">\n",
    "    <!-- Left Column -->\n",
    "    <div style=\"width: 45%; padding: 10px;\">\n",
    "    <ul>\n",
    "      <li><b>An Open-source</b> framework for connecting:</li>\n",
    "        <ul>\n",
    "          <li>LLMs</li>\n",
    "          <li>Data sources</li>\n",
    "          <li>Other functionality under a <b>unified syntax</b></li>\n",
    "        </ul>\n",
    "      <li>Allows for scalability</li>\n",
    "      <li>Contains modular components</li>\n",
    "      <li>Supports <b>Python</b> and <b>Javascript</b></li>\n",
    "    </ul>\n",
    "    LangChain encompasses an entire ecosystem of tools, but in this course, we'll focus on the core components of the LangChain library: LLMs, including open-source and proprietary models, prompts, chains, agents, and document retrievers. \n",
    "    </div>\n",
    "    <!-- Right Column -->\n",
    "    <div style=\"width: 48%; padding: 10px;\">\n",
    "    <div>\n",
    "    <img src='./images/components-of-lc.png' width=70%>\n",
    "    </div>\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "### **Hugging Face**\n",
    "\n",
    "- __Open-source__ repository of models, datasets, and tools\n",
    "\n",
    "Accessing LLMs hosted on Hugging Face is free, but isong them in LangChain requires creating a Hugging Face API key.\n",
    "\n",
    "### **Standardizing syntax**\n",
    "\n",
    "Now we have our key, let's use LangChain to use a model from Hugging Face, and compare it to using an OpenAI model. LangChain has OpenAI and HuggingFace classes for interacting with the respective APIs. \n",
    "\n",
    "<div style=\"display: flex;\">\n",
    "  <!-- Left Column -->\n",
    "  <div style=\"width: 45%; padding: 10px;\">\n",
    "    <b>Hugging Face (Falcon-7b)</b>:\n",
    "  </div>\n",
    "  <!-- Separation Line -->\n",
    "  <div style=\"width: 2px; background-color: DodgerBlue; margin: 0 10px;\"></div>  <!-- Right Column -->\n",
    "  <div style=\"width: 48%; padding: 10px;\">\n",
    "    <b>OpenAI (gpt-3.5-turpo-instruct)</b>:\n",
    "  </div>\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Get the API key\n",
    "hf_api_key = os.getenv('HF_API_KEY')\n",
    "\n",
    "# Verify the API key was loaded (optional)\n",
    "if hf_api_key is None:\n",
    "    raise ValueError(\"HF_API_KEY not found in .env file\")\n",
    "\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id= \"tiiuae/falcon-7b-instruct\",\n",
    "    huggingfacehub_api_token=hf_api_key\n",
    ")\n",
    "\n",
    "question = \"Can you still have fun\"\n",
    "output = llm.invoke(question)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
