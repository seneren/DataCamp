{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case Study\n",
    "\n",
    "## Re-cap\n",
    "\n",
    "### 1 - Zip function\n",
    "\n",
    "The zip function accepts an arbitrary number of iterables and returns an iterator of tuples.\n",
    "\n",
    "```python\n",
    "avengers = ['hawkeye', 'iron man', 'thor', 'quicksilver']\n",
    "names = ['barton', 'stark', 'odinson', 'maximoff']\n",
    "z = zip(avengers, names)\n",
    "print(type(z))\n",
    "\n",
    "<class 'zip'>\n",
    "\n",
    "print(list(z))\n",
    "\n",
    "[('hawkeye', 'barton'), ('iron man', 'stark'), ('thor', 'odinson'), ('quicksilver', 'maximoff')]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Defining a function\n",
    "\n",
    "For writing functions, function headers begin with the keyword def, followed by the function name, arguments inside parentheses and a colon. We then have the function body, with the docstrings enclosed in triple quotation marks; the rest of the function body performs the computation that the function does and closes with the keyword return, followed by the value or values to return.\n",
    "\n",
    "```python\n",
    "def raise_both(value1, value2):\n",
    "    \"\"\"Raise value1 to the power of value2 and vice versa.\"\"\"\n",
    "    new_value1 = value1 ** value2\n",
    "    new_value2 = value2 ** value1\n",
    "    new_tuple = (new_value1, new_value2)\n",
    "    return new_tuple\n",
    "\n",
    "print(raise_both(3, 4))\n",
    "\n",
    "(81, 64)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 - List comprehensions\n",
    "\n",
    "Comprehensions, in their most basic forms, are enclosed in square brackets and are structured as output expression for iterator variable in iterable. More advanced comprehensions can include conditionals on the output expression and/or conditionals on the iterable.\n",
    "\n",
    "* Basic\n",
    "    ```python\n",
    "    [output expression for iterator variable in iterable]\n",
    "    ```\n",
    "\n",
    "* Advanced\n",
    "    ```python\n",
    "    [output expression +\n",
    "    conditional on output for iterator variable in iterable +\n",
    "    conditional on iterable]\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Zipping Dictionaries__\n",
    "\n",
    "_Instructions_\n",
    "\n",
    "* Create a zip object by calling `zip()` and passing to it `feature_names and `row_vals`. Assign the result to `zipped_lists`.\n",
    "* Create a dictionary from the `zipped_lists` zip object by calling `dict()` with `zipped_lists`. Assign the resulting dictionary to `rs_dict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CountryName': 'Arab World', 'CountryCode': 'ARB', 'IndicatorName': 'Adolescent fertility rate (births per 1,000 women ages 15-19)', 'IndicatorCode': 'SP.ADO.TFRT', 'Year': '1960', 'Value': '133.56090740552298'}\n"
     ]
    }
   ],
   "source": [
    "feature_names = ['CountryName',\n",
    " 'CountryCode',\n",
    " 'IndicatorName',\n",
    " 'IndicatorCode',\n",
    " 'Year',\n",
    " 'Value']\n",
    "row_vals = ['Arab World',\n",
    " 'ARB',\n",
    " 'Adolescent fertility rate (births per 1,000 women ages 15-19)',\n",
    " 'SP.ADO.TFRT',\n",
    " '1960',\n",
    " '133.56090740552298']\n",
    "\n",
    "# Zip lists: zipped_lists\n",
    "zipped_lists = zip(feature_names, row_vals)\n",
    "\n",
    "# Create a dictionary: rs_dict\n",
    "rs_dict = dict(zipped_lists)\n",
    "\n",
    "# Print the dictionary\n",
    "print(rs_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Writing a function to help us__\n",
    "\n",
    "In this exercise, we will create a function to house the code we wrote earlier to make things easier and much more concise. Why? This way, we only need to call the function and supply the appropriate lists to create your dictionaries! \n",
    "\n",
    "_Instructions_\n",
    "* Define the function `lists2dict()` with two parameters: `list1` and `list2`.\n",
    "* Return the resulting dictionary `rs_dict` in `lists2dict()`.\n",
    "* Call the `lists2dict()` function with the arguments `feature_names` and `row_vals`. Assign the result of the function call to `rs_fxn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Country Name': 'Arab World', 'Country Code': 'ARB', 'Indicator Name': 'Adolescent fertility rate (births per 1,000 women ages 15-19)', 'Indicator Code': 'SP.ADO.TFRT', 'Year': '1960', 'Value': '133.56090740552298'}\n"
     ]
    }
   ],
   "source": [
    "# feature_names and row_vals have been preloaded from the previous exercise\n",
    "\n",
    "def lists2dict(list1, list2):\n",
    "    \"\"\"Return a dictionary where list1 providesthe keys and list2 provides the values.\"\"\"\n",
    "\n",
    "    # Zip lists: zipped_lists\n",
    "    zipped_lists = zip(list1, list2)\n",
    "\n",
    "    # Create a dictionary: rs_dict\n",
    "    rs_dict = dict(zipped_lists)\n",
    "\n",
    "    # Return the dictionary\n",
    "    return rs_dict\n",
    "\n",
    "# Call lists2dict: rs_fxn\n",
    "rs_fxn = lists2dict(feature_names, row_vals)\n",
    "\n",
    "# Print rs_fxn\n",
    "print(rs_fxn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Using a list comprehension__\n",
    "\n",
    "This time, we're going to use the `lists2dict()` function we defined in the last exercise to turn a bunch of lists into a list of dictionaries with the help of a list comprehension.\n",
    "\n",
    "The `lists2dict()` function has already been defined above.\n",
    "\n",
    "Our goal is to use a list comprehension to generate a list of dicts, where the keys are the header names and the values are the row entries.\n",
    "\n",
    "_Instructions_\n",
    "* Inspect the contents of `row_lists` by printing the first two lists in `row_lists`.\n",
    "* Create a list comprehension that generates a dictionary using `lists2dict()` for each sublist in `row_lists`. The keys are from the `feature_names` list and the values are the row entries in `row_lists`. Use `sublist` as your iterator variable and assign the reulting list of dictionaries to `list_of_dicts`.\n",
    "* Look at the first two dictionaries in your new list of dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Arab World', 'ARB', 'Adolescent fertility rate (births per 1,000 women ages 15-19)', 'SP.ADO.TFRT', 1960, 133.56090740552298]\n",
      "['Arab World', 'ARB', 'Age dependency ratio (% of working-age population)', 'SP.POP.DPND', 1960, 87.7976011532547] \n",
      "\n",
      "{'Country Name': 'Arab World', 'Country Code': 'ARB', 'Indicator Name': 'Adolescent fertility rate (births per 1,000 women ages 15-19)', 'Indicator Code': 'SP.ADO.TFRT', 'Year': 1960, 'Value': 133.56090740552298}\n",
      "{'Country Name': 'Arab World', 'Country Code': 'ARB', 'Indicator Name': 'Age dependency ratio (% of working-age population)', 'Indicator Code': 'SP.POP.DPND', 'Year': 1960, 'Value': 87.7976011532547}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../Databases/World-Development-Indicators/WDICSV_subset.csv')\n",
    "\n",
    "feature_names = list(df.columns)  \n",
    "row_lists = df.values.tolist()  \n",
    "\n",
    "lists2dict(feature_names, row_lists[0])     # lists2dict is already defined in the previous exercise\n",
    "\n",
    "# Print out first two lists in row_lists\n",
    "print(row_lists[0])\n",
    "print(row_lists[1], '\\n')\n",
    "\n",
    "# Turn list of lists into list of dicts: list_of_dicts\n",
    "list_of_dicts = [lists2dict(feature_names, sublist) for sublist in row_lists]\n",
    "\n",
    "# Print the first two dictionaries in list_of_dicts\n",
    "print(list_of_dicts[0])\n",
    "print(list_of_dicts[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Turning this all into a DataFrame__\n",
    "\n",
    "We've zipped lists together, created a function to house your code, and even used the function in a list comprehension to generate a list of dictionaries.\n",
    "\n",
    "We will now use all of these to convert the list of dictionaries into a pandas DataFrame. We will see how convenient it is to generate a DataFrame from dictionaries with the `DataFrame()` function from the pandas package.\n",
    "\n",
    "The `lists2dict()` function, `feature_names` list, and `row_lists` list have been preloaded for this exercise.\n",
    "\n",
    "_Instructions_\n",
    "* To use the `DataFrame()` function you need, first import the pandas package with the alias `pd`.\n",
    "* Create a DataFrame from the list of dictionaries in `list_of_dicts` by calling `pd.DataFrame()`. Assign the resulting DataFrame to `df`.\n",
    "* Inspect the contents of `df` printing the head of the DataFrame. Head of the DataFrame `df` can be accessed by calling `df.head()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Country Name Country Code                                     Indicator Name  Indicator Code  Year         Value\n",
      "0   Arab World          ARB  Adolescent fertility rate (births per 1,000 wo...     SP.ADO.TFRT  1960  1.335609e+02\n",
      "1   Arab World          ARB  Age dependency ratio (% of working-age populat...     SP.POP.DPND  1960  8.779760e+01\n",
      "2   Arab World          ARB  Age dependency ratio, old (% of working-age po...  SP.POP.DPND.OL  1960  6.634579e+00\n",
      "3   Arab World          ARB  Age dependency ratio, young (% of working-age ...  SP.POP.DPND.YG  1960  8.102333e+01\n",
      "4   Arab World          ARB        Arms exports (SIPRI trend indicator values)  MS.MIL.XPRT.KD  1960  3.000000e+06\n"
     ]
    }
   ],
   "source": [
    "# pandas is imported as pd, list_of_dicts is available from the previous exercise\n",
    "\n",
    "df = pd.DataFrame(list_of_dicts)\n",
    "\n",
    "# Print the head of the DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Python generators for streaming data\n",
    "\n",
    "### Processing data in chunks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__The following code is an exception for the course procedure: In order to match the data used in DataCamp, the csv file `WDICSV.csv` has been modified and extracted as `WDICSV_world_dev_ind_datacamp.csv`. It still has much more data comparing to the original `world_dev_ind.csv` file.\n",
    "Skip the next code cell to avoid downloading the file again, and move on to the one after it.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Only look at this cell if you want to see how the csv file explained above was modified.\"\"\"\n",
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv('../Databases/World-Development-Indicators/WDICSV.csv')\n",
    "\n",
    "# Define the feature names\n",
    "feature_names = ['CountryName', 'CountryCode', 'IndicatorName', 'IndicatorCode', 'Year', 'Value']\n",
    "\n",
    "# Create the row_lists\n",
    "row_lists = []\n",
    "for index, row in df.iterrows():\n",
    "    if pd.notna(row['1960']):\n",
    "        row_list = [\n",
    "            row['Country Name'],\n",
    "            row['Country Code'],\n",
    "            row['Indicator Name'],\n",
    "            row['Indicator Code'],\n",
    "            1960,\n",
    "            row['1960']\n",
    "        ]\n",
    "        row_lists.append(row_list)\n",
    "\n",
    "# Create a new DataFrame from the row_lists with the specified column names\n",
    "filtered_df = pd.DataFrame(row_lists, columns=feature_names)\n",
    "\n",
    "# Save the filtered DataFrame to a new CSV file. Remove \"#\" from the next line to save the file if there's no at /Databases/World-Development-Indicators\"\n",
    "# filtered_df.to_csv('../Databases/World-Development-Indicators/WDICSV_world_dev_ind_datacamp.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXERCISE\n",
    "\n",
    "The csv file `'WDICSVworld_dev_ind_datacamp.csv'` is in the directory for our use (check if it's there). To begin, we need to open a connection to this file using what is known as a context manager. For example, the command `with open('datacamp.csv')` as datacamp binds the csv file `'datacamp.csv' as datacamp` in the context manager. Here, the `with` statement is the context manager, and its purpose is to ensure that resources are efficiently allocated when opening a connection to a file.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "* Use `open()` to bind the csv file `'WDICSVworld_dev_ind_datacamp.csv'` as file in the context manager.\n",
    "* Complete the `for` loop so that it iterates __1000__ times to perform the loop body and process only the first 1000 rows of data of the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Africa Eastern and Southern': 125, 'Africa Western and Central': 122, 'Arab World': 120, 'Caribbean small states': 118, 'Central Europe and the Baltics': 114, 'Early-demographic dividend': 152, 'East Asia & Pacific': 173, 'East Asia & Pacific (excluding high income)': 76}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv('../Databases/World-Development-Indicators/WDICSV_world_dev_ind_datacamp.csv')\n",
    "\n",
    "\n",
    "# Open a connection to the file\n",
    "with open('../Databases/World-Development-Indicators/WDICSV_world_dev_ind_datacamp.csv') as file:\n",
    "\n",
    "    # Skip the column names\n",
    "    file.readline()\n",
    "\n",
    "    # Initialize an empty dictionary: counts_dict\n",
    "    counts_dict = {}\n",
    "\n",
    "    # Process only the first 1000 rows\n",
    "    for j in range(1000):     # csv file has over 35000 rows, but we only process the first 1000 rows for speed\n",
    "\n",
    "        # Split the current line into a list: line\n",
    "        line = file.readline().split(',')\n",
    "\n",
    "        # Get the value for the first column: first_col\n",
    "        first_col = line[0]\n",
    "\n",
    "        # If the column value is in the dict, increment its value\n",
    "        if first_col in counts_dict.keys():\n",
    "            counts_dict[first_col] += 1\n",
    "\n",
    "        # Else, add to the dict and set value to 1\n",
    "        else:\n",
    "            counts_dict[first_col] = 1\n",
    "\n",
    "# Print the resulting dictionary\n",
    "print(counts_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing a generator to load data in chunks\n",
    "\n",
    "In this case, it would be useful to use generators. Generators allow users to [lazily evaluate](https://www.blog.pythonlibrary.org/2014/01/27/python-201-an-intro-to-generators/) data. This concept of _lazy evaluation_ is useful when you have to deal with very large datasets because it lets you generate values in an efficient manner by yielding only chunks of data at a time instead of the whole thing at once.\n",
    "\n",
    "In this exercise, we will define a generator function `read_large_file()` that produces a generator object which yields a single line from a file each time `next()` is called on it. The csv file `'WDICSV_world_dev_ind_datacamp.csv'` is in the directory for our use.\n",
    "\n",
    "Note that when you open a connection to a file, the resulting file object is already a generator! So out in the wild, you won't have to explicitly create generator objects in cases such as this. But for pedagogical reasons, we are having you practice how to do this here with the `read_large_file()` coroutine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "\n",
    "* In the function `read_large_file()`, read a line from file_object by using the method `readline()`. Assign the result to `data`.\n",
    "* In the function read_large_file(), yield the line read from the file `data`.\n",
    "* In the context manager, create a generator object `gen_file` by calling your generator function `read_large_file()` and passing `file` to it.\n",
    "* Print the first three lines produced by the generator object `gen_file` using `next()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountryName,CountryCode,IndicatorName,IndicatorCode,Year,Value\n",
      "\n",
      "Africa Eastern and Southern,AFE,\"Adolescent fertility rate (births per 1,000 women ages 15-19)\",SP.ADO.TFRT,1960,135.79329065051937\n",
      "\n",
      "Africa Eastern and Southern,AFE,Age dependency ratio (% of working-age population),SP.POP.DPND,1960,88.96769659511115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define read_large_file()\n",
    "def read_large_file(file_object):\n",
    "    \"\"\"A generator function to read a large file lazily.\"\"\"\n",
    "\n",
    "    # Loop indefinitely until the end of the file\n",
    "    while True:\n",
    "\n",
    "        # Read a line from the file: data\n",
    "        data = file_object.readline()\n",
    "\n",
    "        # Break if this is the end of the file\n",
    "        if not data:\n",
    "            break\n",
    "\n",
    "        # Yield the line of data\n",
    "        yield data\n",
    "\n",
    "# Open a connection to the file\n",
    "with open('../Databases/World-Development-Indicators/WDICSV_world_dev_ind_datacamp.csv') as file:\n",
    "\n",
    "    # Create a generator object for the file: gen_file\n",
    "    gen_file = read_large_file(file)\n",
    "\n",
    "    # Print the first three lines of the file\n",
    "    print(next(gen_file))\n",
    "    print(next(gen_file))\n",
    "    print(next(gen_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use our generator function to process the World Bank dataset like we did previously. We will process the file line by line, to create a dictionary of the counts of how many times each country appears in a column in the dataset. For this exercise, however, we won't process just 1000 rows of data, we'll process the entire dataset!\n",
    "\n",
    "The generator function `read_large_file()` and the csv file `'WDICSV_world_dev_ind_datacamp.csv'` are preloaded from the previous exercise and ready for our use.\n",
    "\n",
    "### Instructions\n",
    "* Bind the file `'WDICSV_world_dev_ind_datacamp.csv'` to `file` in the context manager with `open()`.\n",
    "* Complete the for loop so that it iterates over the generator from the call to `read_large_file()` to process all the rows of the file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CountryName': 1, 'Africa Eastern and Southern': 125, 'Africa Western and Central': 122, 'Arab World': 120, 'Caribbean small states': 118, 'Central Europe and the Baltics': 114, 'Early-demographic dividend': 152, 'East Asia & Pacific': 173, 'East Asia & Pacific (excluding high income)': 169, 'East Asia & Pacific (IDA & IBRD countries)': 143, 'Euro area': 137, 'Europe & Central Asia': 153, 'Europe & Central Asia (excluding high income)': 145, 'Europe & Central Asia (IDA & IBRD countries)': 123, 'European Union': 137, 'Fragile and conflict affected situations': 126, 'Heavily indebted poor countries (HIPC)': 119, 'High income': 166, 'IBRD only': 151, 'IDA & IBRD total': 151, 'IDA blend': 125, 'IDA only': 116, 'IDA total': 119, 'Late-demographic dividend': 144, 'Latin America & Caribbean': 182, 'Latin America & Caribbean (excluding high income)': 183, 'Latin America & the Caribbean (IDA & IBRD countries)': 157, 'Least developed countries: UN classification': 116, 'Low & middle income': 177, 'Low income': 142, 'Lower middle income': 175, 'Middle East & North Africa': 152, 'Middle East & North Africa (excluding high income)': 163, 'Middle East & North Africa (IDA & IBRD countries)': 138, 'Middle income': 177, 'North America': 172, 'OECD members': 147, 'Other small states': 122, 'Pacific island small states': 101, 'Post-demographic dividend': 144, 'Pre-demographic dividend': 119, 'Small states': 117, 'South Asia': 197, 'South Asia (IDA & IBRD)': 171, 'Sub-Saharan Africa': 150, 'Sub-Saharan Africa (excluding high income)': 150, 'Sub-Saharan Africa (IDA & IBRD countries)': 126, 'Upper middle income': 177, 'World': 156, 'Afghanistan': 144, 'Albania': 96, 'Algeria': 200, 'American Samoa': 86, 'Andorra': 73, 'Angola': 128, 'Antigua and Barbuda': 101, 'Argentina': 208, 'Armenia': 86, 'Aruba': 87, 'Australia': 234, 'Austria': 168, 'Azerbaijan': 86, '\"Bahamas': 114, 'Bahrain': 104, 'Bangladesh': 177, 'Barbados': 116, 'Belarus': 95, 'Belgium': 144, 'Belize': 124, 'Benin': 202, 'Bermuda': 94, 'Bhutan': 87, 'Bolivia': 198, 'Bosnia and Herzegovina': 84, 'Botswana': 172, 'Brazil': 245, 'British Virgin Islands': 102, 'Brunei Darussalam': 112, 'Bulgaria': 101, 'Burkina Faso': 180, 'Burundi': 158, 'Cabo Verde': 102, 'Cambodia': 144, 'Cameroon': 167, 'Canada': 219, 'Cayman Islands': 84, 'Central African Republic': 179, 'Chad': 199, 'Channel Islands': 85, 'Chile': 256, 'China': 153, 'Colombia': 220, 'Comoros': 87, '\"Congo': 340, 'Costa Rica': 234, \"Cote d'Ivoire\": 188, 'Croatia': 84, 'Cuba': 114, 'Curacao': 80, 'Cyprus': 130, 'Czechia': 94, 'Denmark': 184, 'Djibouti': 88, 'Dominica': 99, 'Dominican Republic': 232, 'Ecuador': 250, '\"Egypt': 239, 'El Salvador': 134, 'Equatorial Guinea': 91, 'Eritrea': 86, 'Estonia': 85, 'Eswatini': 125, 'Ethiopia': 151, 'Faroe Islands': 87, 'Fiji': 144, 'Finland': 169, 'France': 258, 'French Polynesia': 92, 'Gabon': 185, '\"Gambia': 106, 'Georgia': 93, 'Germany': 157, 'Ghana': 210, 'Gibraltar': 92, 'Greece': 220, 'Greenland': 87, 'Grenada': 104, 'Guam': 94, 'Guatemala': 233, 'Guinea': 120, 'Guinea-Bissau': 93, 'Guyana': 219, 'Haiti': 155, 'Honduras': 240, '\"Hong Kong SAR': 156, 'Hungary': 142, 'Iceland': 162, 'India': 261, 'Indonesia': 205, '\"Iran': 241, 'Iraq': 167, 'Ireland': 159, 'Isle of Man': 82, 'Israel': 219, 'Italy': 170, 'Jamaica': 181, 'Japan': 188, 'Jordan': 147, 'Kazakhstan': 86, 'Kenya': 211, 'Kiribati': 105, '\"Korea': 354, 'Kosovo': 73, 'Kuwait': 109, 'Kyrgyz Republic': 84, 'Lao PDR': 118, 'Latvia': 84, 'Lebanon': 138, 'Lesotho': 182, 'Liberia': 125, 'Libya': 158, 'Liechtenstein': 80, 'Lithuania': 86, 'Luxembourg': 135, '\"Macao SAR': 105, 'Madagascar': 200, 'Malawi': 111, 'Malaysia': 221, 'Maldives': 95, 'Mali': 104, 'Malta': 129, 'Marshall Islands': 91, 'Mauritania': 113, 'Mauritius': 149, 'Mexico': 241, '\"Micronesia': 91, 'Moldova': 86, 'Monaco': 76, 'Mongolia': 88, 'Montenegro': 80, 'Morocco': 221, 'Mozambique': 118, 'Myanmar': 155, 'Namibia': 91, 'Nauru': 84, 'Nepal': 148, 'Netherlands': 174, 'New Caledonia': 92, 'New Zealand': 164, 'Nicaragua': 199, 'Niger': 182, 'Nigeria': 158, 'North Macedonia': 84, 'Northern Mariana Islands': 84, 'Norway': 182, 'Oman': 121, 'Pakistan': 252, 'Palau': 73, 'Panama': 202, 'Papua New Guinea': 137, 'Paraguay': 154, 'Peru': 256, 'Philippines': 209, 'Poland': 132, 'Portugal': 169, 'Puerto Rico': 141, 'Qatar': 89, 'Romania': 125, 'Russian Federation': 93, 'Rwanda': 175, 'Samoa': 97, 'San Marino': 71, 'Sao Tome and Principe': 94, 'Saudi Arabia': 127, 'Senegal': 193, 'Serbia': 84, 'Seychelles': 121, 'Sierra Leone': 148, 'Singapore': 236, 'Sint Maarten (Dutch part)': 78, 'Slovak Republic': 94, 'Slovenia': 80, 'Solomon Islands': 106, 'Somalia': 190, 'South Africa': 277, 'South Sudan': 83, 'Spain': 170, 'Sri Lanka': 230, 'St. Kitts and Nevis': 98, 'St. Lucia': 97, 'St. Martin (French part)': 76, 'St. Vincent and the Grenadines': 108, 'Sudan': 226, 'Suriname': 147, 'Sweden': 229, 'Switzerland': 183, 'Syrian Arab Republic': 206, 'Tajikistan': 84, 'Tanzania': 147, 'Thailand': 237, 'Timor-Leste': 82, 'Togo': 142, 'Tonga': 98, 'Trinidad and Tobago': 148, 'Tunisia': 139, 'Turkiye': 237, 'Turkmenistan': 84, 'Turks and Caicos Islands': 92, 'Tuvalu': 91, 'Uganda': 192, 'Ukraine': 88, 'United Arab Emirates': 96, 'United Kingdom': 189, 'United States': 200, 'Uruguay': 210, 'Uzbekistan': 86, 'Vanuatu': 105, '\"Venezuela': 207, 'Viet Nam': 126, 'Virgin Islands (U.S.)': 89, 'West Bank and Gaza': 57, '\"Yemen': 104, 'Zambia': 138, 'Zimbabwe': 146}\n"
     ]
    }
   ],
   "source": [
    "# initialize an empty dictionary: counts_dict\n",
    "counts_dict = {}\n",
    "\n",
    "\"\"\"Using generators can be slower than reading in the entire file at once. In practice, for small files, it doesn't matter much.\n",
    "For very large files, however, the difference in processing time can be substantial.\"\"\"\n",
    "\n",
    "# Open a connection to the file\n",
    "with open('../Databases/World-Development-Indicators/WDICSV_world_dev_ind_datacamp.csv') as file:\n",
    "\n",
    "    # Iterate over the generator from read_large_file()\n",
    "    for line in read_large_file(file):\n",
    "        row = line.split(',')\n",
    "        first_col = row[0]\n",
    "\n",
    "        if first_col in counts_dict.keys():\n",
    "            counts_dict[first_col] += 1\n",
    "        else:\n",
    "            counts_dict[first_col] = 1\n",
    "\n",
    "# Print\n",
    "print(counts_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using pandas' read_csv iterator for streaming data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__The following code is an exception for the course procedure: In order to match the data used in DataCamp, the csv file `WDICSV.csv` has been modified and extracted as `WDICSV_ind_pop_datacamp.csv`. It has a bit more rows comparing to the original `ind_pop.csv` file.\n",
    "Skip the next code cell to avoid downloading the file again, and move on to the one after it.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Only look at this cell if you want to see how the csv file explained above was modified.\"\"\"\n",
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv('../Databases/World-Development-Indicators/WDICSV.csv')\n",
    "\n",
    "# Define the feature names\n",
    "feature_names = ['CountryName', 'CountryCode', 'IndicatorName', 'IndicatorCode', 'Year', 'Value']\n",
    "\n",
    "# Get all year columns (assuming they're numeric column names between 1960 and 2023)\n",
    "year_columns = [str(year) for year in range(1960, 2024)]\n",
    "\n",
    "# Create temporary list\n",
    "temp_list = []\n",
    "\n",
    "# Get all year columns\n",
    "year_columns = [str(year) for year in range(1960, 2024)]\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if row['Indicator Name'] == 'Urban population (% of total population)':\n",
    "        for year in year_columns:\n",
    "            if pd.notna(row[year]):\n",
    "                temp_list.append([\n",
    "                    row['Country Name'],\n",
    "                    row['Country Code'],\n",
    "                    row['Indicator Name'],\n",
    "                    row['Indicator Code'],\n",
    "                    int(year),\n",
    "                    row[year]\n",
    "                ])\n",
    "\n",
    "# Create a new DataFrame from the row_lists with the specified column names\n",
    "filtered_df = pd.DataFrame(row_lists, columns=feature_names)\n",
    "\n",
    "# Then sort the DataFrame by the 'Year' column\n",
    "filtered_df = filtered_df.sort_values(['Year', 'CountryName'])\n",
    "\n",
    "# Save the filtered DataFrame to a new CSV file. Remove \"#\" from the next line to save the file if there's no at /Databases/World-Development-Indicators\"\n",
    "# filtered_df.to_csv('../Databases/World-Development-Indicators/WDICSV_ind_pop_datacamp.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   CountryName CountryCode                             IndicatorName      IndicatorCode  Year  Value\n",
      "0                  Afghanistan         AFG  Urban population (% of total population)  SP.URB.TOTL.IN.ZS  1960   8.40\n",
      "1  Africa Eastern and Southern         AFE  Urban population (% of total population)  SP.URB.TOTL.IN.ZS  1960  14.58\n",
      "2   Africa Western and Central         AFW  Urban population (% of total population)  SP.URB.TOTL.IN.ZS  1960  14.71\n",
      "3                      Albania         ALB  Urban population (% of total population)  SP.URB.TOTL.IN.ZS  1960  30.70\n",
      "4                      Algeria         DZA  Urban population (% of total population)  SP.URB.TOTL.IN.ZS  1960  30.51\n",
      "5               American Samoa         ASM  Urban population (% of total population)  SP.URB.TOTL.IN.ZS  1960  66.21\n",
      "6                      Andorra         AND  Urban population (% of total population)  SP.URB.TOTL.IN.ZS  1960  58.45\n",
      "7                       Angola         AGO  Urban population (% of total population)  SP.URB.TOTL.IN.ZS  1960  10.44\n",
      "8          Antigua and Barbuda         ATG  Urban population (% of total population)  SP.URB.TOTL.IN.ZS  1960  39.66\n",
      "9                   Arab World         ARB  Urban population (% of total population)  SP.URB.TOTL.IN.ZS  1960  31.01\n",
      "     CountryName CountryCode                             IndicatorName      IndicatorCode  Year  Value\n",
      "10     Argentina         ARG  Urban population (% of total population)  SP.URB.TOTL.IN.ZS  1960  73.61\n",
      "11       Armenia         ARM  Urban population (% of total population)  SP.URB.TOTL.IN.ZS  1960  51.27\n",
      "12         Aruba         ABW  Urban population (% of total population)  SP.URB.TOTL.IN.ZS  1960  50.78\n",
      "13     Australia         AUS  Urban population (% of total population)  SP.URB.TOTL.IN.ZS  1960  81.53\n",
      "14       Austria         AUT  Urban population (% of total population)  SP.URB.TOTL.IN.ZS  1960  64.72\n",
      "15    Azerbaijan         AZE  Urban population (% of total population)  SP.URB.TOTL.IN.ZS  1960  52.66\n",
      "16  Bahamas, The         BHS  Urban population (% of total population)  SP.URB.TOTL.IN.ZS  1960  59.71\n",
      "17       Bahrain         BHR  Urban population (% of total population)  SP.URB.TOTL.IN.ZS  1960  82.32\n",
      "18    Bangladesh         BGD  Urban population (% of total population)  SP.URB.TOTL.IN.ZS  1960   5.13\n",
      "19      Barbados         BRB  Urban population (% of total population)  SP.URB.TOTL.IN.ZS  1960  36.78\n"
     ]
    }
   ],
   "source": [
    "# Import the pandas package\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize reader object: df_reader\n",
    "df_reader = pd.read_csv('../Databases/World-Development-Indicators/WDICSV_ind_pop_datacamp.csv', chunksize=10)\n",
    "\n",
    "# Print two chunks\n",
    "print(next(df_reader))\n",
    "print(next(df_reader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous exercise, we used `read_csv()` to read in DataFrame chunks from a large dataset. In this exercise, we will read in a file using a bigger DataFrame chunk size and then process the data from the first chunk.\n",
    "\n",
    "To process the data, we will create another DataFrame composed of only the rows from a specific country. You will then zip together two of the columns from the new DataFrame,  ~~`'Total Population'`~~ `Year` and ~~`'Urban population (% of total population)'`~~ `Value` . Finally, we will create a list of tuples from the zip object, where each tuple is composed of a value from each of the two columns mentioned.\n",
    "\n",
    "`pandas` has been imported as pd.\n",
    "\n",
    "### Instructions\n",
    "* Use `pd.read_csv()` to read in the file in `../Databases/World-Development-Indicators/WDICSV_ind_pop_datacamp.csv` in chunks of size `1000`. Assign the result to `urb_pop_reader`.\n",
    "\n",
    "* Get the first DataFrame chunk from the iterable `urb_pop_reader` and assign this to `df_urb_pop`.\n",
    "\n",
    "* Select only the rows of `df_urb_pop` that have a `'CountryCode'` of `'CEB'`. To do this, compare whether `df_urb_pop['CountryCode']` is equal to `'CEB'` within the square brackets in `df_urb_pop[____]`.\n",
    "\n",
    "* Using `zip()`, zip together the ~~`'Total Population'`~~ `Year` and ~~`'Urban population (% of total population)'`~~ `Value` columns of `df_pop_ceb`. Assign the resulting zip object to `pops`.\n",
    "\n",
    "__Note:__ On the Datacamp course the columns were `'Total Population'` and `'Urban population (% of total population)'`. However, since we cannot access the original database, we will use the `Year` and `Value` columns instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   CountryName CountryCode                             IndicatorName      IndicatorCode  Year  Value\n",
      "0                  Afghanistan         AFG  Urban population (% of total population)  SP.URB.TOTL.IN.ZS  1960   8.40\n",
      "1  Africa Eastern and Southern         AFE  Urban population (% of total population)  SP.URB.TOTL.IN.ZS  1960  14.58\n",
      "2   Africa Western and Central         AFW  Urban population (% of total population)  SP.URB.TOTL.IN.ZS  1960  14.71\n",
      "3                      Albania         ALB  Urban population (% of total population)  SP.URB.TOTL.IN.ZS  1960  30.70\n",
      "4                      Algeria         DZA  Urban population (% of total population)  SP.URB.TOTL.IN.ZS  1960  30.51\n",
      "[(1960, 44.50789271439007), (1961, 45.2073380737434), (1962, 45.8673685184926), (1963, 46.5349208922556)]\n"
     ]
    }
   ],
   "source": [
    "# Initialize reader object: urb_pop_reader\n",
    "urb_pop_reader = pd.read_csv('../Databases/World-Development-Indicators/WDICSV_ind_pop_datacamp.csv', chunksize=1000)\n",
    "\n",
    "# Get the first DataFrame chunk: df_urb_pop\n",
    "df_urb_pop = next(urb_pop_reader)\n",
    "\n",
    "# Check out the head of the DataFrame\n",
    "print(df_urb_pop.head())\n",
    "\n",
    "# Check out specific country: df_pop_ceb\n",
    "df_pop_ceb = df_urb_pop[df_urb_pop['CountryCode'] == 'CEB']\n",
    "\n",
    "# Zip DataFrame columns of interest: pops\n",
    "pops = zip(df_pop_ceb['Year'], df_pop_ceb['Value'])\n",
    "\n",
    "# Turn zip object into list: pops_list\n",
    "pops_list = list(pops)\n",
    "\n",
    "# Print pops_list\n",
    "print(pops_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
