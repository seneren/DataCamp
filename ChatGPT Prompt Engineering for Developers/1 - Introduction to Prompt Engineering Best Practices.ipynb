{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Message Roles**\n",
    "\n",
    "<img src='./images/system-roles.png' width=75% height=75%>\n",
    "\n",
    "* __System message__: guides model behavior\n",
    "* __User message__: prompt from the user.\n",
    "* __Assistant message__: response to user propmt\n",
    "\n",
    "To ask \"What is prompt engineering?\" via the API, we set up the client by calling the OpenAI class and setting the api_key. Then, we call the chat.completions.create() function, specifying the model and messages as a list of dictionaries with the role and content. We set the temperature to zero for deterministic answers and do not specify max_tokens to allow full responses. Finally, we print the response.\n",
    "\n",
    "```python\n",
    "prompt = \"What is prompt engineering?\"\n",
    "\n",
    "client = OpenAI(api_key=\"<OPENAI_API_KEY>))\n",
    "response = client.chat.completions.create(\n",
    "    model = \"gpt-3.5-turbo\",\n",
    "    messages[\n",
    "        {\"role\": \"user\",\n",
    "        \"content\": prompt}],\n",
    "        temperature = 0\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)\n",
    "```\n",
    "\n",
    "Output: <br>\n",
    "<img src=\"./images/prompt-engineering-response.png\" width=90% height=90%>\n",
    "\n",
    "To avoid writing it every time, we wrap the code inside a function named `get_response` that takes a prompt as input and sends it to the API just as before. Instead of printing the response, the function returns it as output. Now, we can call this function with one line of code and save the returned value in a variable we can print.\n",
    "\n",
    "```python\n",
    "def get_response(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model = 'gpt-3.5-turbo',\n",
    "        messages = [\n",
    "            {'role': 'user',\n",
    "            'content': prompt}],\n",
    "            temperature = 0\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "prompt = \"What is prompt engineering?\"\n",
    "response = get_response(prompt)\n",
    "print(response)\n",
    "```\n",
    "\n",
    "The output is the same as before. <br>\n",
    "<img src=\"./images/prompt-engineering-response.png\" width=90% height=90%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Key principles of prompt engineering**\n",
    "\n",
    "### **Using action verbs**\n",
    "\n",
    "When asking the model to perform certain tasks, opt for action verbs that explicitly guide the model's task. Conversely, avoid using ambiguous verbs.\n",
    "\n",
    "<table style=\"width:40%; border-collapse: collapse; margin: auto;\">\n",
    "  <tr>\n",
    "    <th style=\"background-color: dodgerblue; color: white; padding: 10px; border: 1px solid black; text-align: center;\">Verbs to Use</th>\n",
    "    <th style=\"background-color: lightcoral; color: black; padding: 10px; border: 1px solid black; text-align: center;\">Verbs to Avoid</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td style=\"padding: 10px; border: 1px solid black; text-align: center;\">write</td>\n",
    "    <td style=\"padding: 10px; border: 1px solid black; text-align: center;\">understand</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td style=\"padding: 10px; border: 1px solid black; text-align: center;\">complete</td>\n",
    "    <td style=\"padding: 10px; border: 1px solid black; text-align: center;\">think</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td style=\"padding: 10px; border: 1px solid black; text-align: center;\">explain</td>\n",
    "    <td style=\"padding: 10px; border: 1px solid black; text-align: center;\">feel</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td style=\"padding: 10px; border: 1px solid black; text-align: center;\">describe</td>\n",
    "    <td style=\"padding: 10px; border: 1px solid black; text-align: center;\">try</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td style=\"padding: 10px; border: 1px solid black; text-align: center;\">evaluate</td>\n",
    "    <td style=\"padding: 10px; border: 1px solid black; text-align: center;\">know</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td style=\"padding: 10px; border: 1px solid black; text-align: center;\">...</td>\n",
    "    <td style=\"padding: 10px; border: 1px solid black; text-align: center;\">...</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "A prompt asking the model to `think about deforestation` is ineffective. While the model generates some output, it remains vague and the prompt needs greater clarity on what is being asked. For example, we can use an action verb to guide the model to a specific task: `proposing strategies to reduce deforestation`.\n",
    "\n",
    "When crafting prompts, we'll want to provide specific, descriptive, and detailed instructions about:\n",
    "* context\n",
    "* output length\n",
    "* format and style\n",
    "* audience\n",
    "\n",
    "A prompt asking to tell us about dogs is too broad. However, when we ask:\n",
    "\n",
    "```python\n",
    "prompt = \"Write a descriptive paragraph about the behavior and characteristics of Golden Retrievers, highlighting their friendly nature, intelligence, and suitability as family pets.\"\n",
    "```\n",
    "\n",
    "we get a more precise answer with the details we've requested, including characteristics and suitability for families.\n",
    "\n",
    "\n",
    "__Crafting a well-structured prompt with delimiters__\n",
    "\n",
    "* Start prompt with instructions\n",
    "* Use delimiters (parentheses, brackets, backticks etc.) to specify input parts*\n",
    "* Mention which delimiters are used\n",
    " \n",
    "This helps the model locate the input. \n",
    "In the following example, we use triple backticks to delimit input text for summarization.\n",
    "\n",
    "```python\n",
    "prompt = \"\"\"Summarize the text delimited by triple backticks into bullet points.\n",
    "        ```TEXT GOES HERE```\"\"\"\n",
    "response =get_response(prompt)\n",
    "```\n",
    "\n",
    "__Using f-strings__\n",
    "\n",
    "Instead of including long inputs within the prompt string, we can use Python's f-strings to embed a pre-defined string. In this example we define the variable `text`, add an `'f'` before the prompt string, and place the text variable in curly brackets inside the prompt. This incorporates the variable's content into the prompt. \n",
    "\n",
    "```python\n",
    "text = \"This is a sample text to summarize\"\n",
    "prompt = f\"\"\"Summarize the text delimited by triple backticks into bullet points.\n",
    "        ```{text}```\"\"\"\n",
    "print(prompt)\n",
    "```\n",
    "Output: <br>\n",
    "<img src='./images/f-string_prompt.png' width=60% height=60%>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Structured putputs and conditional prompts**\n",
    "\n",
    "__Structured outputs__\n",
    "\n",
    "When a custom output format is needed, one approach is to break down the prompt into parts.\n",
    "\n",
    "Here we define an input text, such as the opening of a fairytale about a boy named David. We then instruct the model to generate an appropriate title, and specify the output format for the text and title. We combine the instructions, output format, and input text in the final prompt. \n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "text = \"Once upon a time in a quaint little village, there lived a curious young boy named David. David was [...]\"\n",
    "instructions = \"You will be provided with a text delimited by triple backticks. Generate a suitable title for it.\"\n",
    "\n",
    "output_format = \"\"\"Use the following format for the output:\n",
    "        - Text: <text we want to title>\n",
    "        -title: <the generated title>\"\"\"\n",
    "\n",
    "prompt = instructions + output_format + f\"```{text}```\"\n",
    "print(get_response(prompt))\n",
    "```\n",
    "This ensures the output meets our requirements, providing a title for David's adventures, with the original text, in the requested format.\n",
    "\n",
    "Output: <br>\n",
    "<img src='./images/structured_output.png' width=70% height=70%>\n",
    "\n",
    "### **Conditional prompts**\n",
    "\n",
    "* Incorporate logic or conditions\n",
    "* Conditional prompts follow an if-else style\n",
    "\n",
    "Suppose we want the model to suggest a title for some provided text, but only if the text is in English. To do that, we explicitly mention this condition in the prompt. If the text is in another language, we tell the model to inform users that it only understands English. Now, for a French text describing my favorite season, the output will be `'I only understand English'`.\n",
    "\n",
    "```python\n",
    "text = \"Le printemps est ma saison préférée. Quand les premières fleurs commencent à éclore, et que les arbres se parent de feuilles vertes et tendres, je me sens revivre [...]\"\n",
    "\n",
    "prompt = f\"\"\"You will be provided with a text delimited by triple backticks.\n",
    "         If the text is written in English, suggest a suitable title for it.\n",
    "         Otherwise, write 'I only understand English'.\n",
    "         ```{text}```\"\"\"\n",
    "\n",
    "pring(get_response(prompt))\n",
    "```\n",
    "\n",
    "Output: <br>\n",
    "\n",
    "`I only understand English`\n",
    "\n",
    "We can incorporate multiple conditions in our prompt. For instance, we might tell the model to generate titles only for English texts containing the keyword 'technology'. <br>\n",
    "If the text is written in English, we check if it contains the keyword. If it does, the model suggests a title. Otherwise, it responds with `'keyword not found'`.\n",
    "\n",
    "```python\n",
    "text = \"In the heart of the forest, sunlight filters through the lush green canopy, creating a tranquil atmosphere [...] \"\n",
    "\n",
    "prompt = f\"\"\"You will be provided with a text delimited by triple backticks.\n",
    "         If the text is written in English, check if it contains the keyword 'technology'.\n",
    "         If it does, suggest a suitable title for it, otherwise, write 'Keyword not found'.\n",
    "         If the text is not written in English, reply with 'I only understand English'.\n",
    "         ```{text}```\"\"\"\n",
    "print(get_response(prompt))\n",
    "```\n",
    "\n",
    "Output: <br>\n",
    "`Keyword not found`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Text: The sun was setting behind the mountains, casting a warm golden glow across the landscape.\n",
      "- Nr. of sentences: 1\n",
      "- Title: N/A\n",
      "- Language: English\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load the environment variables\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "client = OpenAI(api_key=api_key)\n",
    "text = \"The sun was setting behind the mountains, casting a warm golden glow across the landscape.\"\n",
    "\n",
    "def get_response(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model = 'gpt-3.5-turbo',\n",
    "        messages = [\n",
    "            {'role': 'user',\n",
    "            'content': prompt}],\n",
    "            temperature = 0\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Create the instructions\n",
    "instructions = \"\"\"You will be provided with a text delimited by three backtips.\n",
    "               Infer the language, and the number of the sentences of the text.\n",
    "               If the number of sentences is more than one, generate a suitable title for it.\n",
    "               Otherwise, write 'N/A'.\n",
    "               \"\"\"\n",
    "\n",
    "# Create the output format\n",
    "output_format = \"\"\"Use the following format for the output:\n",
    "                - Text: <the text you are provided>\n",
    "                - Nr. of sentences: <number of sentences in the text>\n",
    "                - Title: <The generated title>\n",
    "                - Language: <the language of the text>\"\"\"\n",
    "\n",
    "prompt = instructions + output_format + f\"```{text}```\"\n",
    "response = get_response(prompt)\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
